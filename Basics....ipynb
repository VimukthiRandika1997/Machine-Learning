{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bec685b1-dfea-4b59-8946-1439a26fbce8",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "\n",
    "- tokenization is the step of breaking down a string into atomic units used in the model\n",
    "- There're several tokenization strategies...\n",
    "- Optimal splitting of words into subunits is usuallay learned from the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084c07ee-ef78-429a-995f-4c435860bd68",
   "metadata": {},
   "source": [
    "## Character Tokenization\n",
    "\n",
    "- Simplest tokenization scheme, feeding each character individually to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "495e3649-d1cf-40ad-9bc2-0722c08b049f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', 'o', 'k', 'e', 'n', 'i', 'z', 'i', 'n', 'g', ' ', 't', 'e', 'x', 't', ' ', 'i', 's', ' ', 'a', ' ', 'c', 'o', 'r', 'e', ' ', 't', 'a', 'k', 's', ' ', 'o', 'f', ' ', 'N', 'L', 'P']\n"
     ]
    }
   ],
   "source": [
    "text = 'Tokenizing text is a core taks of NLP'\n",
    "tokenized_text = list(text)\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3efd3a9-b700-429b-a7d3-003656483be1",
   "metadata": {},
   "source": [
    "Models expect each character to be converted to an integer, this process called *Numericalization*\n",
    "\n",
    "- One simple way to do this is by encoding each unqiue token with a unique integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aab2da6-8db8-4ee1-b994-30be4b8e8a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, 'L': 1, 'N': 2, 'P': 3, 'T': 4, 'a': 5, 'c': 6, 'e': 7, 'f': 8, 'g': 9, 'i': 10, 'k': 11, 'n': 12, 'o': 13, 'r': 14, 's': 15, 't': 16, 'x': 17, 'z': 18}\n"
     ]
    }
   ],
   "source": [
    "token2idx = {ch: idx for idx, ch in enumerate(sorted(set(tokenized_text)))}\n",
    "print(token2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2708ebaa-a2e3-4bef-807e-f8f3f5454b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 13, 11, 7, 12, 10, 18, 10, 12, 9, 0, 16, 7, 17, 16, 0, 10, 15, 0, 5, 0, 6, 13, 14, 7, 0, 16, 5, 11, 15, 0, 13, 8, 0, 2, 1, 3]\n"
     ]
    }
   ],
   "source": [
    "# Transform tokenized_text according above mapping\n",
    "\n",
    "input_ids = [token2idx[token] for token in tokenized_text]\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8931ae3f-4f8e-48e6-a6c0-a0da01508e05",
   "metadata": {},
   "source": [
    "Last step is to convert input_ids to a 2D tensor of one-hot vectors.\n",
    "\n",
    "- **one hot** vectors are frequently used in ML to encode categorical data, which can be either ordinal or nomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "741f753a-93c4-415a-af0a-1810fc9deee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c3252f-9ad1-4b74-a6fd-1ac9fc0e2586",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
