{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4468e46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow import keras\n",
    "tf.__version__\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91a7ed07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c20667",
   "metadata": {},
   "source": [
    "# Building an Image Classifier Using the Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf2c1d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using keras to load the dataset\n",
    "# Fashion MNIST\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce0d177f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56014586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f33dfab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make validation set and normalization\n",
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "210631f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76458ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt\",\"Trouser\", \"Pullover\", \n",
    "               \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \n",
    "               \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d4900c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca41b5d",
   "metadata": {},
   "source": [
    "### Creating the model using the Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "490c75ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 10:02:46.016064: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-14 10:02:46.057043: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2699905000 Hz\n",
      "2022-06-14 10:02:46.058040: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fab68620c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-06-14 10:02:46.058121: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-06-14 10:02:46.062157: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8438d7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c83e77f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f282c314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x7f9544406b80>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f9544406f40>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f95443fd8e0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f95443fdc70>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting list of layers\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35a00594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_3'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33a4a797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('dense_3') is hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1fbe927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05301619,  0.06244113,  0.05054692, ...,  0.01764475,\n",
       "        -0.00577062,  0.07239129],\n",
       "       [ 0.04589973, -0.02921166, -0.01609978, ...,  0.05711772,\n",
       "         0.01447737, -0.0386938 ],\n",
       "       [-0.01166113,  0.00910156,  0.05611062, ...,  0.01090199,\n",
       "        -0.02315265, -0.07409004],\n",
       "       ...,\n",
       "       [-0.02471458,  0.07275097, -0.00864197, ..., -0.07119269,\n",
       "         0.061675  ,  0.00472841],\n",
       "       [ 0.03733488, -0.03830429,  0.04277442, ...,  0.01168951,\n",
       "         0.03712864, -0.03298739],\n",
       "       [ 0.0346819 , -0.06444225,  0.01942424, ..., -0.01441158,\n",
       "         0.03039699,  0.03987434]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All the parameters of a layer can be accessed using\n",
    "# get_weights(), set_weights()\n",
    "weights, biases = hidden1.get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e93abe29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d486ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c735d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8f4ff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if we ever want to initialize the connction weights to\n",
    "# different way, we can use kernel_initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6e4d9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=\"sgd\",\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1479af7d",
   "metadata": {},
   "source": [
    "### Trainig and Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79ddd8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 10:02:46.477440: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 10s 5ms/step - loss: 1.0205 - accuracy: 0.6774 - val_loss: 0.5276 - val_accuracy: 0.8194\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.5085 - accuracy: 0.8235 - val_loss: 0.4794 - val_accuracy: 0.8410\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4493 - accuracy: 0.8451 - val_loss: 0.4384 - val_accuracy: 0.8492\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4214 - accuracy: 0.8534 - val_loss: 0.3987 - val_accuracy: 0.8660\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4053 - accuracy: 0.8580 - val_loss: 0.3790 - val_accuracy: 0.8712\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3827 - accuracy: 0.8651 - val_loss: 0.3707 - val_accuracy: 0.8742\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3688 - accuracy: 0.8703 - val_loss: 0.3647 - val_accuracy: 0.8762\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3511 - accuracy: 0.8780 - val_loss: 0.3588 - val_accuracy: 0.8720\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3370 - accuracy: 0.8801 - val_loss: 0.3539 - val_accuracy: 0.8738\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3353 - accuracy: 0.8819 - val_loss: 0.3447 - val_accuracy: 0.8796\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3268 - accuracy: 0.8853 - val_loss: 0.3781 - val_accuracy: 0.8556\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 9s 6ms/step - loss: 0.3209 - accuracy: 0.8852 - val_loss: 0.3481 - val_accuracy: 0.8762\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3125 - accuracy: 0.8866 - val_loss: 0.3263 - val_accuracy: 0.8854\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3049 - accuracy: 0.8908 - val_loss: 0.3260 - val_accuracy: 0.8834\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2948 - accuracy: 0.8940 - val_loss: 0.3141 - val_accuracy: 0.8884\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2913 - accuracy: 0.8942 - val_loss: 0.3162 - val_accuracy: 0.8902\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2856 - accuracy: 0.8977 - val_loss: 0.3111 - val_accuracy: 0.8894\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2776 - accuracy: 0.9010 - val_loss: 0.3146 - val_accuracy: 0.8852\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2802 - accuracy: 0.8996 - val_loss: 0.3210 - val_accuracy: 0.8836\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2651 - accuracy: 0.9047 - val_loss: 0.2967 - val_accuracy: 0.8914\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2648 - accuracy: 0.9052 - val_loss: 0.3022 - val_accuracy: 0.8880\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2594 - accuracy: 0.9080 - val_loss: 0.3038 - val_accuracy: 0.8866\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2515 - accuracy: 0.9104 - val_loss: 0.3148 - val_accuracy: 0.8864\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2549 - accuracy: 0.9075 - val_loss: 0.2933 - val_accuracy: 0.8966\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2490 - accuracy: 0.9099 - val_loss: 0.2887 - val_accuracy: 0.8972\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2464 - accuracy: 0.9104 - val_loss: 0.2970 - val_accuracy: 0.8920\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2408 - accuracy: 0.9139 - val_loss: 0.2873 - val_accuracy: 0.8982\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2368 - accuracy: 0.9161 - val_loss: 0.2950 - val_accuracy: 0.8934\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2287 - accuracy: 0.9184 - val_loss: 0.2983 - val_accuracy: 0.8942\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2279 - accuracy: 0.9170 - val_loss: 0.2992 - val_accuracy: 0.8928\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                   validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2528e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vetical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f82f448",
   "metadata": {},
   "source": [
    "We can see that both training accuracy and the validation accuracy steadily increase during training, while the training loss and the validation loss decrease. Also, the validation curves are close to the training curves, which means there is not too much overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7334cde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 59.7650 - accuracy: 0.8575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[59.76502990722656, 0.8575000166893005]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eavluating the model using test set\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c9fd57",
   "metadata": {},
   "source": [
    "It is common to get slightly lower performance on the test set than on the validation set, because the hyperparameters are tuned on the validation set, not on the tes set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ad52d5",
   "metadata": {},
   "source": [
    "### Using the model to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ef42d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23b2e24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vimukthi/anaconda3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class with highest estimated probability\n",
    "y_pred = model.predict_classes(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37d38a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U10')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e5a4907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=uint8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here the classifier actually classified all three images correctly\n",
    "y_new = y_test[:3]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23f5ae0",
   "metadata": {},
   "source": [
    "# Building a Regression MLP Using the Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ccc8b96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7798092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataset doesn't have any missing values and only numerical values\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train) # fit to data\n",
    "X_valid = scaler.transform(X_valid)     # center the data\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d87372ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 2.4126 - val_loss: 3.8773\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 2.6722 - val_loss: 0.8083\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.4525 - val_loss: 0.4753\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.4439 - val_loss: 0.4326\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4156 - val_loss: 0.4204\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4012 - val_loss: 0.3994\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4023 - val_loss: 0.3884\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3944 - val_loss: 0.3851\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3701 - val_loss: 0.3749\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3618 - val_loss: 0.3722\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3752 - val_loss: 0.3639\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3662 - val_loss: 0.3636\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3472 - val_loss: 0.3612\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3603 - val_loss: 0.3572\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3452 - val_loss: 0.3507\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3383 - val_loss: 0.3516\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3564 - val_loss: 0.3503\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3622 - val_loss: 0.3437\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3485 - val_loss: 0.3449\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3435 - val_loss: 0.3496\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3379 - val_loss: 0.3486\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3583 - val_loss: 0.3426\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3349 - val_loss: 0.3410\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3378 - val_loss: 0.3396\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3312 - val_loss: 0.3435\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3397 - val_loss: 0.3388\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3420 - val_loss: 0.3389\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3387 - val_loss: 0.3366\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3452 - val_loss: 0.3356\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3391 - val_loss: 0.3379\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.3134\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                   validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3] # pretend these are new instances\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8e4c1d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.3539824],\n",
       "       [1.8712554],\n",
       "       [3.1655774]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b18e2d2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vetical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ddaafb",
   "metadata": {},
   "source": [
    "# Building Complex Models Using the Functional API\n",
    "\n",
    "One example of a nonsequential neural network is a **Wide Deep Neural Networks**. It connects all or part of the inputs directly to the output layer, allowing this architecture makes it possible for the neural network to learn both deep patterns (using the deep path) and simple rules (through the short path). In contrast, a regular MLP forces all the data to flow through the full stack of layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "188f8fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 1.0053 - val_loss: 0.4268\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.4353 - val_loss: 0.3977\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3796 - val_loss: 0.4000\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3892 - val_loss: 0.5862\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4082 - val_loss: 2.2809\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4225 - val_loss: 4.4302\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 8.1226 - val_loss: 0.3618\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3657 - val_loss: 0.3343\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3401 - val_loss: 0.4029\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4229 - val_loss: 0.3607\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3657 - val_loss: 0.3984\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3613 - val_loss: 0.3370\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3449 - val_loss: 0.4149\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.4510 - val_loss: 0.3771\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3270 - val_loss: 0.4139\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3622 - val_loss: 0.3278\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3823 - val_loss: 0.3453\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3219 - val_loss: 0.3033\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2973 - val_loss: 0.3658\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3121 - val_loss: 0.3247\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3075 - val_loss: 0.3126\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3124 - val_loss: 0.2996\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2982 - val_loss: 0.3268\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4175 - val_loss: 0.3190\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3156 - val_loss: 0.3951\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3406 - val_loss: 0.4371\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4216 - val_loss: 0.4146\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3162 - val_loss: 0.3961\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4619 - val_loss: 0.3638\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.2938 - val_loss: 0.3763\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.3475\n",
      "WARNING:tensorflow:11 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f955ce26dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs=[input_], outputs=[output])\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01) # Adam optimizer\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=opt)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                   validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3] # pretend these are new instances\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "438b8bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.103453],\n",
       "       [2.129798],\n",
       "       [3.442926]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f93fa4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim (0, 1) # set the vertical range(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e540c3",
   "metadata": {},
   "source": [
    "When we want to send a subset of the features through the wide path and a different subset through the deep path. One solution is to use multiple inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "46a82e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output])\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a4a9f1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 3s 6ms/step - loss: 1.5810 - main_output_loss: 1.3871 - aux_output_loss: 3.3262 - val_loss: 1.7986 - val_main_output_loss: 1.8366 - val_aux_output_loss: 1.4565\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.7483 - main_output_loss: 0.6829 - aux_output_loss: 1.3366 - val_loss: 0.6254 - val_main_output_loss: 0.5491 - val_aux_output_loss: 1.3117\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.6013 - main_output_loss: 0.5277 - aux_output_loss: 1.2639 - val_loss: 0.5306 - val_main_output_loss: 0.4681 - val_aux_output_loss: 1.0931\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5404 - main_output_loss: 0.4775 - aux_output_loss: 1.1068 - val_loss: 0.5289 - val_main_output_loss: 0.4824 - val_aux_output_loss: 0.9479\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.5104 - main_output_loss: 0.4608 - aux_output_loss: 0.9563 - val_loss: 0.4647 - val_main_output_loss: 0.4244 - val_aux_output_loss: 0.8276\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4558 - main_output_loss: 0.4150 - aux_output_loss: 0.8225 - val_loss: 0.4374 - val_main_output_loss: 0.4043 - val_aux_output_loss: 0.7357\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4515 - main_output_loss: 0.4184 - aux_output_loss: 0.7493 - val_loss: 0.4292 - val_main_output_loss: 0.4010 - val_aux_output_loss: 0.6832\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4342 - main_output_loss: 0.4045 - aux_output_loss: 0.7018 - val_loss: 0.4174 - val_main_output_loss: 0.3921 - val_aux_output_loss: 0.6449\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4377 - main_output_loss: 0.4110 - aux_output_loss: 0.6775 - val_loss: 0.4241 - val_main_output_loss: 0.4020 - val_aux_output_loss: 0.6234\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4321 - main_output_loss: 0.4102 - aux_output_loss: 0.6290 - val_loss: 0.4065 - val_main_output_loss: 0.3858 - val_aux_output_loss: 0.5931\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4072 - main_output_loss: 0.3857 - aux_output_loss: 0.6001 - val_loss: 0.4041 - val_main_output_loss: 0.3854 - val_aux_output_loss: 0.5728\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4037 - main_output_loss: 0.3832 - aux_output_loss: 0.5876 - val_loss: 0.4062 - val_main_output_loss: 0.3890 - val_aux_output_loss: 0.5609\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4305 - main_output_loss: 0.4153 - aux_output_loss: 0.5668 - val_loss: 0.3914 - val_main_output_loss: 0.3742 - val_aux_output_loss: 0.5468\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4077 - main_output_loss: 0.3895 - aux_output_loss: 0.5713 - val_loss: 0.3907 - val_main_output_loss: 0.3750 - val_aux_output_loss: 0.5328\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3988 - main_output_loss: 0.3836 - aux_output_loss: 0.5352 - val_loss: 0.3891 - val_main_output_loss: 0.3746 - val_aux_output_loss: 0.5204\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.3841 - main_output_loss: 0.3681 - aux_output_loss: 0.5283 - val_loss: 0.3750 - val_main_output_loss: 0.3601 - val_aux_output_loss: 0.5087\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3707 - main_output_loss: 0.3546 - aux_output_loss: 0.5157 - val_loss: 0.3712 - val_main_output_loss: 0.3571 - val_aux_output_loss: 0.4984\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.5832 - main_output_loss: 0.5860 - aux_output_loss: 0.5577 - val_loss: 0.3738 - val_main_output_loss: 0.3598 - val_aux_output_loss: 0.4995\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3767 - main_output_loss: 0.3624 - aux_output_loss: 0.5051 - val_loss: 0.3874 - val_main_output_loss: 0.3741 - val_aux_output_loss: 0.5067\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.3869 - main_output_loss: 0.3736 - aux_output_loss: 0.5064 - val_loss: 0.3710 - val_main_output_loss: 0.3587 - val_aux_output_loss: 0.4820\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.3536 - main_output_loss: 0.3388 - aux_output_loss: 0.4866\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f95441ec0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                   validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7e955b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[3.0479825],\n",
       "        [1.8463501],\n",
       "        [3.161716 ]], dtype=float32),\n",
       " array([[3.0961056],\n",
       "        [1.7075285],\n",
       "        [2.8827615]], dtype=float32)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "71fa9f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling multiple outputs\n",
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output, aux_output])\n",
    "# Each output will need its own loss function\n",
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1d4cf37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 4s 8ms/step - loss: 0.3745 - main_output_loss: 0.3611 - aux_output_loss: 0.4952 - val_loss: 0.3599 - val_main_output_loss: 0.3472 - val_aux_output_loss: 0.4743\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3742 - main_output_loss: 0.3615 - aux_output_loss: 0.4889 - val_loss: 0.3643 - val_main_output_loss: 0.3524 - val_aux_output_loss: 0.4712\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3789 - main_output_loss: 0.3672 - aux_output_loss: 0.4844 - val_loss: 0.3702 - val_main_output_loss: 0.3589 - val_aux_output_loss: 0.4723\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.3755 - main_output_loss: 0.3640 - aux_output_loss: 0.4790 - val_loss: 0.3874 - val_main_output_loss: 0.3778 - val_aux_output_loss: 0.4737\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3850 - main_output_loss: 0.3751 - aux_output_loss: 0.4740 - val_loss: 0.3566 - val_main_output_loss: 0.3456 - val_aux_output_loss: 0.4556\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3677 - main_output_loss: 0.3563 - aux_output_loss: 0.4698 - val_loss: 0.3578 - val_main_output_loss: 0.3472 - val_aux_output_loss: 0.4527\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3669 - main_output_loss: 0.3558 - aux_output_loss: 0.4670 - val_loss: 0.3525 - val_main_output_loss: 0.3423 - val_aux_output_loss: 0.4443\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3606 - main_output_loss: 0.3496 - aux_output_loss: 0.4597 - val_loss: 0.3554 - val_main_output_loss: 0.3458 - val_aux_output_loss: 0.4414\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.4100 - main_output_loss: 0.3995 - aux_output_loss: 0.5045 - val_loss: 0.3556 - val_main_output_loss: 0.3454 - val_aux_output_loss: 0.4470\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.3639 - main_output_loss: 0.3539 - aux_output_loss: 0.4540 - val_loss: 0.3580 - val_main_output_loss: 0.3485 - val_aux_output_loss: 0.4441\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.3629 - main_output_loss: 0.3530 - aux_output_loss: 0.4516 - val_loss: 0.3467 - val_main_output_loss: 0.3372 - val_aux_output_loss: 0.4323\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.3596 - main_output_loss: 0.3499 - aux_output_loss: 0.4472 - val_loss: 0.3488 - val_main_output_loss: 0.3394 - val_aux_output_loss: 0.4337\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3538 - main_output_loss: 0.3440 - aux_output_loss: 0.4421 - val_loss: 0.3572 - val_main_output_loss: 0.3492 - val_aux_output_loss: 0.4296\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3553 - main_output_loss: 0.3457 - aux_output_loss: 0.4416 - val_loss: 0.3435 - val_main_output_loss: 0.3346 - val_aux_output_loss: 0.4239\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.3512 - main_output_loss: 0.3416 - aux_output_loss: 0.4380 - val_loss: 0.3512 - val_main_output_loss: 0.3435 - val_aux_output_loss: 0.4203\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3493 - main_output_loss: 0.3399 - aux_output_loss: 0.4332 - val_loss: 0.3376 - val_main_output_loss: 0.3289 - val_aux_output_loss: 0.4153\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3466 - main_output_loss: 0.3374 - aux_output_loss: 0.4293 - val_loss: 0.3371 - val_main_output_loss: 0.3284 - val_aux_output_loss: 0.4152\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3504 - main_output_loss: 0.3415 - aux_output_loss: 0.4296 - val_loss: 0.3353 - val_main_output_loss: 0.3270 - val_aux_output_loss: 0.4101\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.3503 - main_output_loss: 0.3416 - aux_output_loss: 0.4283 - val_loss: 0.3328 - val_main_output_loss: 0.3246 - val_aux_output_loss: 0.4068\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.3456 - main_output_loss: 0.3369 - aux_output_loss: 0.4236 - val_loss: 0.3450 - val_main_output_loss: 0.3376 - val_aux_output_loss: 0.4111\n"
     ]
    }
   ],
   "source": [
    "# When we train the model, we need to provide labels for each output.\n",
    "history = model.fit(\n",
    "            [X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
    "            validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a717088c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 1s 3ms/step - loss: 0.3271 - main_output_loss: 0.3171 - aux_output_loss: 0.4173\n"
     ]
    }
   ],
   "source": [
    "# keras provides some useful info\n",
    "total_loss, main_loss, aux_loss = model.evaluate(\n",
    "                                        [X_test_A, X_test_B], [y_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dc3d0226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.2213407]\n",
      " [1.8097172]\n",
      " [2.9004574]]\n",
      "[[3.322624 ]\n",
      " [1.6937568]\n",
      " [2.6837652]]\n"
     ]
    }
   ],
   "source": [
    "# predict() returns predictoins for each output\n",
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])\n",
    "print(y_pred_main)\n",
    "print(y_pred_aux)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be2f34e",
   "metadata": {},
   "source": [
    "# Using the Subclassing API to Build Dynamic Models\n",
    "\n",
    "Both the Sequential API and the Functional API are declarative: start with declaring which layers we want and how they should be connected, and only then data is fed for training or inference. Hence the model is static.\n",
    "\n",
    "Some models involve loops, varying shapes, conditional branching, and other dynamic behaviors. For that case, Subclass API can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "37285732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model\n",
    "class WideAndDeepModel(keras.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs) # handles standard args (e.g., name)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "    \n",
    "model = WideAndDeepModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b5a241",
   "metadata": {},
   "source": [
    "# Saving and Restoring a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "652f680d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.Sequential([...])\n",
    "# model.compile([....])\n",
    "# model.fit([....])\n",
    "# model.save(\"my_keras_model.h5\")\n",
    "\n",
    "### Loading a model \n",
    "# model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1aaf79",
   "metadata": {},
   "source": [
    "# Using callbacks\n",
    "\n",
    "callbacks can be used to save the checkpoints of the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ead277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .... build and compile the model\n",
    "checkpint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\")\n",
    "history = model.fit(X_train, y_train, epochs=10, callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18313d2",
   "metadata": {},
   "source": [
    "The ModelCheckpoint callback saves checkpoints of the model at regular intervals during training, by default at the end of each epoch.\n",
    "\n",
    "If we use a validation set during training, we can use **save_best_only=True** when creating ModelCheckpoint. It will only save the model when its performance on the validation set is the best so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0c5ace12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple way to implement early stopping\n",
    "# checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)\n",
    "# history = model.fit(X_train, y_train, epochs=10,validation_data=(X_valid, y_valid), callbacks=[checkpoint_cb])\n",
    "# model = keras.models.load_model(\"my_keras_model.h5\") # roll back to best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7922883",
   "metadata": {},
   "source": [
    "Another way to implement early stopping is to use the **EarlyStopping** callback. It will interrupt training when it measures no progress on the validation set for a number of epochs(defined by patient argument), and it will optionally roll back to the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4f1f7c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Combining both checkpoints and early stopping\n",
    "#early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "#history = model.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "33c6160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating custom callbacks\n",
    "# shows the ratio between the validation loss and training loss during training -> detects overfitting\n",
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))\n",
    "        \n",
    "# There're much more,\n",
    "# on_train_begin(), on_train_end(), on_epoch_begin(), on_epoch_end(),\n",
    "# on_batch_begin(), on_batch_end()\n",
    "\n",
    "# For evaluation\n",
    "# on_test_begin(), on_test_end(), on_test_batch_begin(), on_test_batch_end()\n",
    "\n",
    "# For prediction\n",
    "# on_predict_begin(), on_predict_end(), on_predict_batch_begin(), on_predict_batch_end()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3c513a",
   "metadata": {},
   "source": [
    "# Using TensorBoard for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "380f7e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m%_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir() # /my_logs/run_2019_06_07-15_15_22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "acccd407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .. Build and compile the model\n",
    "#tensorboard_db = keras.callbacks.TensorBoard(run_logdir)\n",
    "#history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid), callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f3ce57",
   "metadata": {},
   "source": [
    "This will create the log directory and during training it will create event files and write summaries to them.\n",
    "\n",
    "Next we need to start the TensorBoard server.\n",
    "- tensorboard --logdir=./my_logs --port=6006\n",
    "\n",
    "Runnig in jupyter-notebook\n",
    "- %load_ext tensorboard\n",
    "- %tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2efca5",
   "metadata": {},
   "source": [
    "# Fine-Tuning Neural Network Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "346826cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One option is to simply try many combinations of hyperparameters and\n",
    "# see which one works best on the validation set (k-fold-cross validation)\n",
    "\n",
    "# We can use GridSearchCV or RandomizedSearchCV to explore the hyperparameter space\n",
    "# to do this, we need to wrap Keras models into objects that mimic regular Scikit-Learn regressors.\n",
    "\n",
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cb021ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a regressor based on this build_model()\n",
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e7e38e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 1.8709 - val_loss: 1.7813\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.2376 - val_loss: 0.7150\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.6596 - val_loss: 0.6114\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5777 - val_loss: 0.5622\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5734 - val_loss: 0.5313\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5337 - val_loss: 0.5077\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.4883 - val_loss: 0.4900\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4768 - val_loss: 0.4760\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4981 - val_loss: 0.4666\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.4536 - val_loss: 0.4602\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4731 - val_loss: 0.4529\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4460 - val_loss: 0.4467\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4397 - val_loss: 0.4424\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4492 - val_loss: 0.4394\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4436 - val_loss: 0.4367\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4400 - val_loss: 0.4305\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4335 - val_loss: 0.4258\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4265 - val_loss: 0.4233\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.4402 - val_loss: 0.4195\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4286 - val_loss: 0.4173\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.4163 - val_loss: 0.4153\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4256 - val_loss: 0.4117\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4243 - val_loss: 0.4108\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4192 - val_loss: 0.4085\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4151 - val_loss: 0.4066\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4152 - val_loss: 0.4049\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4171 - val_loss: 0.4022\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.4261 - val_loss: 0.4024\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4131 - val_loss: 0.4007\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4181 - val_loss: 0.3972\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3988 - val_loss: 0.3966\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.4027 - val_loss: 0.3942\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4138 - val_loss: 0.3962\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3968 - val_loss: 0.3917\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4165 - val_loss: 0.3914\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.4024 - val_loss: 0.3916\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4085 - val_loss: 0.3871\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3843 - val_loss: 0.3880\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3957 - val_loss: 0.3845\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3912 - val_loss: 0.3850\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3863 - val_loss: 0.3835\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3916 - val_loss: 0.3843\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3777 - val_loss: 0.3828\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3781 - val_loss: 0.3800\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3913 - val_loss: 0.3803\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.4008 - val_loss: 0.3794\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3797 - val_loss: 0.3776\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3698 - val_loss: 0.3763\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3947 - val_loss: 0.3748\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3835 - val_loss: 0.3775\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3886 - val_loss: 0.3766\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3610 - val_loss: 0.3757\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3776 - val_loss: 0.3736\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3726 - val_loss: 0.3752\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3728 - val_loss: 0.3723\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3836 - val_loss: 0.3760\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3637 - val_loss: 0.3700\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3746 - val_loss: 0.3716\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3699 - val_loss: 0.3692\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3959 - val_loss: 0.3719\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3694 - val_loss: 0.3682\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3654 - val_loss: 0.3682\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3675 - val_loss: 0.3685\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3771 - val_loss: 0.3675\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3695 - val_loss: 0.3674\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3972 - val_loss: 0.3677\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3757 - val_loss: 0.3675\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3667 - val_loss: 0.3654\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3738 - val_loss: 0.3685\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3785 - val_loss: 0.3650\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3788 - val_loss: 0.3633\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3736 - val_loss: 0.3637\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3820 - val_loss: 0.3644\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3846 - val_loss: 0.3662\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3658 - val_loss: 0.3614\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3677 - val_loss: 0.3616\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3643 - val_loss: 0.3626\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3617 - val_loss: 0.3620\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3763 - val_loss: 0.3612\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3793 - val_loss: 0.3597\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3705 - val_loss: 0.3621\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3570 - val_loss: 0.3594\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3760 - val_loss: 0.3597\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3520 - val_loss: 0.3613\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3694 - val_loss: 0.3595\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3834 - val_loss: 0.3589\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3633 - val_loss: 0.3597\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3616 - val_loss: 0.3583\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4029 - val_loss: 0.3582\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3684 - val_loss: 0.3570\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3694 - val_loss: 0.3577\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3635 - val_loss: 0.3571\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3613 - val_loss: 0.3577\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3655 - val_loss: 0.3580\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3597 - val_loss: 0.3550\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3790 - val_loss: 0.3562\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3544 - val_loss: 0.3553\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3480 - val_loss: 0.3576\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3682 - val_loss: 0.3549\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3645 - val_loss: 0.3574\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.3331\n",
      "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f955e80fc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "# Now we can use this object like a regular Scikit-Learn regressor\n",
    "# train using fit(), evaluate using score(), make predictions using predict()\n",
    "\n",
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    "             validation_data=(X_valid, y_valid),\n",
    "             callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "mse_test = keras_reg.score(X_test, y_test)\n",
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "594ae0e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3331020176410675"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c31435e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.082893 , 1.4294224, 3.201467 ], dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e5f14821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 5ms/step - loss: 1.2301 - val_loss: 0.7818\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.8159 - val_loss: 0.9270\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 5ms/step - loss: 1.1090 - val_loss: 0.4950\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5042 - val_loss: 0.5024\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4700 - val_loss: 0.6077\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5381 - val_loss: 0.4873\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4597 - val_loss: 0.4762\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4284 - val_loss: 0.4516\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3940 - val_loss: 0.5214\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3839 - val_loss: 0.3983\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3945 - val_loss: 0.4240\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3736 - val_loss: 0.3582\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3446 - val_loss: 0.3520\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3663 - val_loss: 0.3370\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3719 - val_loss: 0.3479\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3515 - val_loss: 0.3492\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3516 - val_loss: 0.3497\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3473 - val_loss: 0.3786\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3403 - val_loss: 0.3535\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3174 - val_loss: 0.3757\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3344 - val_loss: 0.4350\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3154 - val_loss: 0.4526\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3087 - val_loss: 0.4179\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3474 - val_loss: 0.4118\n",
      "121/121 [==============================] - 1s 4ms/step - loss: 0.5996\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 1.1211 - val_loss: 0.7373\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5474 - val_loss: 1.3338\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5917 - val_loss: 0.4796\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 1s 5ms/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 5ms/step - loss: 2.7963 - val_loss: 0.8569\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.8019 - val_loss: 0.7591\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.6880 - val_loss: 0.6948\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6661 - val_loss: 0.6511\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.6031 - val_loss: 0.6212\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5518 - val_loss: 0.5929\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5523 - val_loss: 0.5751\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5240 - val_loss: 0.5560\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4969 - val_loss: 0.5431\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5014 - val_loss: 0.5302\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4807 - val_loss: 0.5219\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4837 - val_loss: 0.5144\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4965 - val_loss: 0.5060\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4983 - val_loss: 0.4998\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4772 - val_loss: 0.4931\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4762 - val_loss: 0.4886\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4547 - val_loss: 0.4812\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4769 - val_loss: 0.4775\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4461 - val_loss: 0.4741\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4498 - val_loss: 0.4710\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4488 - val_loss: 0.4649\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4372 - val_loss: 0.4625\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4472 - val_loss: 0.4622\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4269 - val_loss: 0.4549\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4228 - val_loss: 0.4541\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4498 - val_loss: 0.4504\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4253 - val_loss: 0.4462\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4299 - val_loss: 0.4440\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4095 - val_loss: 0.4399\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4350 - val_loss: 0.4402\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4289 - val_loss: 0.4366\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4139 - val_loss: 0.4353\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3994 - val_loss: 0.4335\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4264 - val_loss: 0.4299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4371 - val_loss: 0.4277\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4272 - val_loss: 0.4297\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4333 - val_loss: 0.4237\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4219 - val_loss: 0.4239\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4019 - val_loss: 0.4205\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3963 - val_loss: 0.4186\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4094 - val_loss: 0.4166\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4122 - val_loss: 0.4159\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3939 - val_loss: 0.4134\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4105 - val_loss: 0.4123\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3930 - val_loss: 0.4127\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4069 - val_loss: 0.4107\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4123 - val_loss: 0.4077\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3918 - val_loss: 0.4055\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3984 - val_loss: 0.4048\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3898 - val_loss: 0.4051\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3782 - val_loss: 0.4019\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4006 - val_loss: 0.4007\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3817 - val_loss: 0.4006\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3777 - val_loss: 0.4014\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3916 - val_loss: 0.3970\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3929 - val_loss: 0.3965\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3647 - val_loss: 0.3959\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3856 - val_loss: 0.3966\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3861 - val_loss: 0.3954\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3827 - val_loss: 0.3921\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3633 - val_loss: 0.3939\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3690 - val_loss: 0.3916\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3855 - val_loss: 0.3926\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3744 - val_loss: 0.3892\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3685 - val_loss: 0.3868\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3828 - val_loss: 0.3889\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3915 - val_loss: 0.3871\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3776 - val_loss: 0.3846\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3661 - val_loss: 0.3839\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3845 - val_loss: 0.3846\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3732 - val_loss: 0.3821\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3603 - val_loss: 0.3824\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3699 - val_loss: 0.3801\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3734 - val_loss: 0.3821\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3784 - val_loss: 0.3815\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3790 - val_loss: 0.3789\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3706 - val_loss: 0.3779\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3728 - val_loss: 0.3787\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3800 - val_loss: 0.3766\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3811 - val_loss: 0.3764\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3683 - val_loss: 0.3763\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3643 - val_loss: 0.3787\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3562 - val_loss: 0.3752\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3634 - val_loss: 0.3735\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3650 - val_loss: 0.3737\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3615 - val_loss: 0.3736\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3511 - val_loss: 0.3725\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3634 - val_loss: 0.3727\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3452 - val_loss: 0.3711\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3613 - val_loss: 0.3708\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3670 - val_loss: 0.3694\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3603 - val_loss: 0.3689\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3607 - val_loss: 0.3713\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3681 - val_loss: 0.3690\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3601 - val_loss: 0.3696\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3817 - val_loss: 0.3710\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3642 - val_loss: 0.3686\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3477 - val_loss: 0.3664\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3355 - val_loss: 0.3664\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3594 - val_loss: 0.3670\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.3906\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 4.2005 - val_loss: 1.0598\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.8637 - val_loss: 0.9183\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.7000 - val_loss: 0.8748\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.6526 - val_loss: 0.8482\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6100 - val_loss: 0.8057\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6130 - val_loss: 0.7759\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5615 - val_loss: 0.7469\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5438 - val_loss: 0.7226\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5106 - val_loss: 0.6950\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5148 - val_loss: 0.6750\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5194 - val_loss: 0.6558\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5075 - val_loss: 0.6362\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5217 - val_loss: 0.6172\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4698 - val_loss: 0.5995\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4745 - val_loss: 0.5849\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4679 - val_loss: 0.5691\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4879 - val_loss: 0.5555\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4839 - val_loss: 0.5449\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4835 - val_loss: 0.5364\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4519 - val_loss: 0.5253\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4311 - val_loss: 0.5161\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4510 - val_loss: 0.5083\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4528 - val_loss: 0.5003\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4471 - val_loss: 0.4935\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4686 - val_loss: 0.4857\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4741 - val_loss: 0.4799\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4364 - val_loss: 0.4741\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4702 - val_loss: 0.4676\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4248 - val_loss: 0.4621\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4408 - val_loss: 0.4567\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4284 - val_loss: 0.4521\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4472 - val_loss: 0.4475\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4292 - val_loss: 0.4427\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4464 - val_loss: 0.4387\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4294 - val_loss: 0.4347\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4225 - val_loss: 0.4317\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4223 - val_loss: 0.4278\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4413 - val_loss: 0.4249\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4279 - val_loss: 0.4221\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4370 - val_loss: 0.4196\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4189 - val_loss: 0.4174\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4177 - val_loss: 0.4148\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4073 - val_loss: 0.4117\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4005 - val_loss: 0.4104\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4203 - val_loss: 0.4095\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4008 - val_loss: 0.4067\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3952 - val_loss: 0.4048\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4120 - val_loss: 0.4032\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4104 - val_loss: 0.4015\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3857 - val_loss: 0.4006\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3899 - val_loss: 0.3991\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4048 - val_loss: 0.3978\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4156 - val_loss: 0.3969\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4039 - val_loss: 0.3962\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3880 - val_loss: 0.3959\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3914 - val_loss: 0.3950\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4072 - val_loss: 0.3936\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3858 - val_loss: 0.3910\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4212 - val_loss: 0.3903\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4244 - val_loss: 0.3892\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3899 - val_loss: 0.3887\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3896 - val_loss: 0.3869\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3826 - val_loss: 0.3865\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3997 - val_loss: 0.3866\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3877 - val_loss: 0.3856\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3872 - val_loss: 0.3833\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3776 - val_loss: 0.3832\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4091 - val_loss: 0.3833\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3832 - val_loss: 0.3818\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3787 - val_loss: 0.3824\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3861 - val_loss: 0.3804\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3639 - val_loss: 0.3791\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3959 - val_loss: 0.3815\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3832 - val_loss: 0.3779\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3837 - val_loss: 0.3767\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3712 - val_loss: 0.3757\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3892 - val_loss: 0.3759\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3787 - val_loss: 0.3747\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3825 - val_loss: 0.3740\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3646 - val_loss: 0.3735\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3669 - val_loss: 0.3736\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3611 - val_loss: 0.3716\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3642 - val_loss: 0.3708\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3735 - val_loss: 0.3700\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3688 - val_loss: 0.3694\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3667 - val_loss: 0.3700\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3556 - val_loss: 0.3694\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3549 - val_loss: 0.3678\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3609 - val_loss: 0.3679\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3625 - val_loss: 0.3666\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3677 - val_loss: 0.3657\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3823 - val_loss: 0.3652\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3640 - val_loss: 0.3640\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3583 - val_loss: 0.3644\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3665 - val_loss: 0.3630\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3484 - val_loss: 0.3639\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3701 - val_loss: 0.3645\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3690 - val_loss: 0.3623\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3658 - val_loss: 0.3621\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3641 - val_loss: 0.3610\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.3637\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 3.0186 - val_loss: 0.9546\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.8298 - val_loss: 0.7781\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.8117 - val_loss: 0.7221\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6131 - val_loss: 0.6588\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.6145 - val_loss: 0.6259\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6285 - val_loss: 0.5687\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5559 - val_loss: 0.5443\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5400 - val_loss: 0.5280\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5215 - val_loss: 0.5118\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5285 - val_loss: 0.4992\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5025 - val_loss: 0.4898\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4848 - val_loss: 0.4813\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4704 - val_loss: 0.4737\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4750 - val_loss: 0.4674\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4616 - val_loss: 0.4620\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4490 - val_loss: 0.4567\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4618 - val_loss: 0.4526\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4489 - val_loss: 0.4485\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4551 - val_loss: 0.4488\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4376 - val_loss: 0.4428\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4573 - val_loss: 0.4411\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4729 - val_loss: 0.4362\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4192 - val_loss: 0.4352\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4434 - val_loss: 0.4312\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4086 - val_loss: 0.4296\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4161 - val_loss: 0.4276\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4337 - val_loss: 0.4261\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4187 - val_loss: 0.4219\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4193 - val_loss: 0.4205\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4347 - val_loss: 0.4187\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4262 - val_loss: 0.4196\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4210 - val_loss: 0.4148\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4333 - val_loss: 0.4145\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4230 - val_loss: 0.4125\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4238 - val_loss: 0.4122\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4333 - val_loss: 0.4087\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4227 - val_loss: 0.4116\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4119 - val_loss: 0.4067\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4047 - val_loss: 0.4051\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4038 - val_loss: 0.4060\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4160 - val_loss: 0.4063\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4139 - val_loss: 0.4043\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4199 - val_loss: 0.4022\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4301 - val_loss: 0.4031\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4047 - val_loss: 0.3990\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3972 - val_loss: 0.3982\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4064 - val_loss: 0.3974\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4183 - val_loss: 0.3948\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4057 - val_loss: 0.3950\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4054 - val_loss: 0.3929\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4102 - val_loss: 0.3932\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3938 - val_loss: 0.3911\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3807 - val_loss: 0.3923\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3925 - val_loss: 0.3890\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3976 - val_loss: 0.3915\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4040 - val_loss: 0.3885\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4102 - val_loss: 0.3914\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3997 - val_loss: 0.3896\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3898 - val_loss: 0.3948\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4209 - val_loss: 0.3862\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3962 - val_loss: 0.3892\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3866 - val_loss: 0.3847\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3923 - val_loss: 0.3853\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4002 - val_loss: 0.3817\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3876 - val_loss: 0.3828\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3891 - val_loss: 0.3814\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3889 - val_loss: 0.3802\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3751 - val_loss: 0.3792\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3985 - val_loss: 0.3801\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3865 - val_loss: 0.3775\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3851 - val_loss: 0.3776\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4082 - val_loss: 0.3781\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3795 - val_loss: 0.3768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3643 - val_loss: 0.3766\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3796 - val_loss: 0.3742\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3767 - val_loss: 0.3747\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3787 - val_loss: 0.3750\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3606 - val_loss: 0.3731\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3797 - val_loss: 0.3733\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3869 - val_loss: 0.3741\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3750 - val_loss: 0.3714\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3725 - val_loss: 0.3758\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3959 - val_loss: 0.3721\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3872 - val_loss: 0.3730\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3644 - val_loss: 0.3699\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3779 - val_loss: 0.3701\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3834 - val_loss: 0.3670\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3725 - val_loss: 0.3696\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3594 - val_loss: 0.3674\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3770 - val_loss: 0.3713\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3709 - val_loss: 0.3668\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3749 - val_loss: 0.3706\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3684 - val_loss: 0.3653\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3778 - val_loss: 0.3789\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3879 - val_loss: 0.3654\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3530 - val_loss: 0.3688\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3631 - val_loss: 0.3637\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3570 - val_loss: 0.3673\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3595 - val_loss: 0.3628\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3721 - val_loss: 0.3670\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3678\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 5ms/step - loss: 1.4079 - val_loss: 0.5849\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5561 - val_loss: 0.5129\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5018 - val_loss: 0.4994\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4558 - val_loss: 0.4752\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4399 - val_loss: 0.4484\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4430 - val_loss: 0.4418\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4218 - val_loss: 0.4442\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4229 - val_loss: 0.4187\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4138 - val_loss: 0.4098\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4039 - val_loss: 0.4116\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4096 - val_loss: 0.4023\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4013 - val_loss: 0.3962\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3760 - val_loss: 0.3978\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3872 - val_loss: 0.3964\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3733 - val_loss: 0.3959\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3803 - val_loss: 0.3792\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3668 - val_loss: 0.3812\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3684 - val_loss: 0.3777\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3643 - val_loss: 0.3693\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3646 - val_loss: 0.3680\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3588 - val_loss: 0.3628\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3451 - val_loss: 0.3616\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3707 - val_loss: 0.3655\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3666 - val_loss: 0.3596\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3625 - val_loss: 0.3578\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3386 - val_loss: 0.3608\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3443 - val_loss: 0.3499\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3227 - val_loss: 0.3470\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3410 - val_loss: 0.3471\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3505 - val_loss: 0.3431\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3347 - val_loss: 0.3393\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3383 - val_loss: 0.3424\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3342 - val_loss: 0.3471\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3353 - val_loss: 0.3426\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3213 - val_loss: 0.3612\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3301 - val_loss: 0.3331\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3278 - val_loss: 0.3444\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3163 - val_loss: 0.3374\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3185 - val_loss: 0.3402\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3100 - val_loss: 0.3361\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3269 - val_loss: 0.3300\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2927 - val_loss: 0.3317\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3258 - val_loss: 0.3421\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3137 - val_loss: 0.3355\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3206 - val_loss: 0.3241\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3000 - val_loss: 0.3272\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3040 - val_loss: 0.3281\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3038 - val_loss: 0.3216\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3002 - val_loss: 0.3220\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2940 - val_loss: 0.3232\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3052 - val_loss: 0.3373\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3244 - val_loss: 0.3204\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3076 - val_loss: 0.3545\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3042 - val_loss: 0.3199\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3202 - val_loss: 0.3226\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3011 - val_loss: 0.3169\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3097 - val_loss: 0.3276\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2862 - val_loss: 0.3368\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2818 - val_loss: 0.3171\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2896 - val_loss: 0.3156\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2983 - val_loss: 0.3240\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2945 - val_loss: 0.3181\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2957 - val_loss: 0.3251\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2869 - val_loss: 0.3123\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2920 - val_loss: 0.3147\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3010 - val_loss: 0.3296\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2771 - val_loss: 0.3156\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3041 - val_loss: 0.3114\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2960 - val_loss: 0.3305\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2750 - val_loss: 0.3113\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3026 - val_loss: 0.3120\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2937 - val_loss: 0.3145\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2889 - val_loss: 0.3186\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2870 - val_loss: 0.3095\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2846 - val_loss: 0.3112\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3026 - val_loss: 0.3110\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2894 - val_loss: 0.3165\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3032 - val_loss: 0.3296\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2817 - val_loss: 0.3105\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2950 - val_loss: 0.3060\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2929 - val_loss: 0.3288\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2950 - val_loss: 0.3317\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2832 - val_loss: 0.3154\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2962 - val_loss: 0.3086\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2845 - val_loss: 0.3100\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2858 - val_loss: 0.3285\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2833 - val_loss: 0.3363\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2879 - val_loss: 0.3112\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2753 - val_loss: 0.3095\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2782 - val_loss: 0.3087\n",
      "121/121 [==============================] - 1s 4ms/step - loss: 0.3247\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 1.6559 - val_loss: 0.6297\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6385 - val_loss: 0.5548\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5578 - val_loss: 0.5160\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4886 - val_loss: 0.4856\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4552 - val_loss: 0.4642\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4334 - val_loss: 0.4563\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4563 - val_loss: 0.4457\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4338 - val_loss: 0.4429\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4172 - val_loss: 0.4346\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4260 - val_loss: 0.4288\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3846 - val_loss: 0.4336\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3889 - val_loss: 0.4432\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.6324 - val_loss: 0.4202\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3944 - val_loss: 0.4073\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3849 - val_loss: 0.3983\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4043 - val_loss: 0.3944\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3869 - val_loss: 0.3921\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3794 - val_loss: 0.3874\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3903 - val_loss: 0.3904\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3815 - val_loss: 0.3868\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3848 - val_loss: 0.3723\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3626 - val_loss: 0.3769\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3592 - val_loss: 0.3639\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3496 - val_loss: 0.3625\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3716 - val_loss: 0.3639\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3678 - val_loss: 0.3554\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3548 - val_loss: 0.3584\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3490 - val_loss: 0.3548\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3549 - val_loss: 0.3519\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3761 - val_loss: 0.3440\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3457 - val_loss: 0.3441\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3279 - val_loss: 0.3429\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3570 - val_loss: 0.3471\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3452 - val_loss: 0.3405\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3415 - val_loss: 0.3475\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3412 - val_loss: 0.3373\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3529 - val_loss: 0.3374\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3384 - val_loss: 0.3388\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3225 - val_loss: 0.3408\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3311 - val_loss: 0.3538\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3330 - val_loss: 0.3377\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3441 - val_loss: 0.3386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3194 - val_loss: 0.3359\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3384 - val_loss: 0.3424\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3433 - val_loss: 0.3450\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3508 - val_loss: 0.3481\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3356 - val_loss: 0.3454\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3317 - val_loss: 0.3458\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3189 - val_loss: 0.3553\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3208 - val_loss: 0.3568\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3154 - val_loss: 0.3513\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3311 - val_loss: 0.3578\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3275 - val_loss: 0.3598\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.4365\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 5ms/step - loss: 1.9896 - val_loss: 1.0267\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 1.6862 - val_loss: 0.6937\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.8828 - val_loss: 0.5405\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5413 - val_loss: 0.4640\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4711 - val_loss: 0.4523\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4617 - val_loss: 0.4275\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4344 - val_loss: 0.4193\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4166 - val_loss: 0.4125\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4331 - val_loss: 0.4032\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3979 - val_loss: 0.4018\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3763 - val_loss: 0.3976\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4106 - val_loss: 0.3879\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4034 - val_loss: 0.3873\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3715 - val_loss: 0.3764\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3797 - val_loss: 0.3767\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3714 - val_loss: 0.3932\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3754 - val_loss: 0.3669\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3674 - val_loss: 0.3615\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3713 - val_loss: 0.3739\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3863 - val_loss: 0.3656\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3565 - val_loss: 0.3629\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3395 - val_loss: 0.3599\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3607 - val_loss: 0.3590\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3609 - val_loss: 0.3522\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3470 - val_loss: 0.3518\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3545 - val_loss: 0.3486\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3378 - val_loss: 0.3584\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3455 - val_loss: 0.3468\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3401 - val_loss: 0.3523\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3259 - val_loss: 0.3458\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3466 - val_loss: 0.3424\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3405 - val_loss: 0.3618\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3251 - val_loss: 0.3509\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3451 - val_loss: 0.3440\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3493 - val_loss: 0.3402\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3354 - val_loss: 0.3481\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3201 - val_loss: 0.3439\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3249 - val_loss: 0.3441\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3351 - val_loss: 0.3456\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3226 - val_loss: 0.3435\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3345 - val_loss: 0.3397\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3240 - val_loss: 0.3359\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3338 - val_loss: 0.3386\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3404 - val_loss: 0.3465\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3249 - val_loss: 0.3419\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3314 - val_loss: 0.3394\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3214 - val_loss: 0.3334\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3380 - val_loss: 0.3322\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3337 - val_loss: 0.3297\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3213 - val_loss: 0.3412\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3131 - val_loss: 0.3333\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3440 - val_loss: 0.3357\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2974 - val_loss: 0.3319\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3031 - val_loss: 0.3203\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3327 - val_loss: 0.3328\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3043 - val_loss: 0.3351\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3150 - val_loss: 0.3339\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3166 - val_loss: 0.3316\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2962 - val_loss: 0.3218\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3217 - val_loss: 0.3234\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3187 - val_loss: 0.3300\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3015 - val_loss: 0.3208\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3171 - val_loss: 0.3314\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3337 - val_loss: 0.3201\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3128 - val_loss: 0.3323\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3136 - val_loss: 0.3313\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3251 - val_loss: 0.3387\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3063 - val_loss: 0.3322\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3065 - val_loss: 0.3337\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2809 - val_loss: 0.3219\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3078 - val_loss: 0.3285\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3098 - val_loss: 0.3154\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3103 - val_loss: 0.3180\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2981 - val_loss: 0.3211\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2931 - val_loss: 0.3223\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3153 - val_loss: 0.3220\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3103 - val_loss: 0.3166\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2969 - val_loss: 0.3252\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3069 - val_loss: 0.3189\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2889 - val_loss: 0.3180\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.3106 - val_loss: 0.3148\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3049 - val_loss: 0.3204\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2845 - val_loss: 0.3175\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3019 - val_loss: 0.3204\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3107 - val_loss: 0.3328\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3063 - val_loss: 0.3212\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3015 - val_loss: 0.3285\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2826 - val_loss: 0.3139\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2909 - val_loss: 0.3158\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2906 - val_loss: 0.3138\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2938 - val_loss: 0.3119\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3103 - val_loss: 0.3111\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2934 - val_loss: 0.3139\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2800 - val_loss: 0.3384\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2917 - val_loss: 0.3131\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2936 - val_loss: 0.3208\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2987 - val_loss: 0.3115\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2808 - val_loss: 0.3089\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.2763 - val_loss: 0.3397\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2819 - val_loss: 0.3144\n",
      "121/121 [==============================] - 1s 4ms/step - loss: 0.3185\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 3s 10ms/step - loss: 5.5108 - val_loss: 3.1291\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 2.6503 - val_loss: 1.6866\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 1.4308 - val_loss: 1.0732\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.9553 - val_loss: 0.8080\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.7351 - val_loss: 0.6899\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.6145 - val_loss: 0.6352\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6033 - val_loss: 0.6080\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5730 - val_loss: 0.5939\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5525 - val_loss: 0.5857\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5542 - val_loss: 0.5802\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5536 - val_loss: 0.5767\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5722 - val_loss: 0.5734\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5520 - val_loss: 0.5715\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5691 - val_loss: 0.5695\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5364 - val_loss: 0.5671\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5477 - val_loss: 0.5651\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5751 - val_loss: 0.5636\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5551 - val_loss: 0.5627\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5460 - val_loss: 0.5608\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5493 - val_loss: 0.5599\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5509 - val_loss: 0.5584\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5033 - val_loss: 0.5568\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5320 - val_loss: 0.5564\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5491 - val_loss: 0.5550\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5375 - val_loss: 0.5545\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5311 - val_loss: 0.5528\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5569 - val_loss: 0.5517\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5441 - val_loss: 0.5511\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5355 - val_loss: 0.5509\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5551 - val_loss: 0.5506\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5628 - val_loss: 0.5488\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5542 - val_loss: 0.5492\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5571 - val_loss: 0.5477\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5197 - val_loss: 0.5478\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5183 - val_loss: 0.5475\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5067 - val_loss: 0.5462\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5429 - val_loss: 0.5455\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5335 - val_loss: 0.5453\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5479 - val_loss: 0.5445\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5506 - val_loss: 0.5438\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5321 - val_loss: 0.5433\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5439 - val_loss: 0.5437\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5309 - val_loss: 0.5428\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5565 - val_loss: 0.5422\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4876 - val_loss: 0.5424\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5239 - val_loss: 0.5426\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5429 - val_loss: 0.5416\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5307 - val_loss: 0.5411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5248 - val_loss: 0.5407\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4970 - val_loss: 0.5413\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5227 - val_loss: 0.5405\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5194 - val_loss: 0.5411\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5349 - val_loss: 0.5408\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5402 - val_loss: 0.5398\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5468 - val_loss: 0.5406\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5229 - val_loss: 0.5396\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5260 - val_loss: 0.5390\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5601 - val_loss: 0.5400\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5249 - val_loss: 0.5387\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5262 - val_loss: 0.5383\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5261 - val_loss: 0.5391\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5312 - val_loss: 0.5394\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5101 - val_loss: 0.5393\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5322 - val_loss: 0.5380\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5371 - val_loss: 0.5378\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5351 - val_loss: 0.5374\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5107 - val_loss: 0.5376\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5164 - val_loss: 0.5374\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5186 - val_loss: 0.5382\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5185 - val_loss: 0.5385\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5284 - val_loss: 0.5375\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5191 - val_loss: 0.5370\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5320 - val_loss: 0.5366\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5250 - val_loss: 0.5376\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4968 - val_loss: 0.5372\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5428 - val_loss: 0.5378\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5150 - val_loss: 0.5375\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5517 - val_loss: 0.5367\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5174 - val_loss: 0.5374\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5123 - val_loss: 0.5364\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5011 - val_loss: 0.5373\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5183 - val_loss: 0.5375\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5442 - val_loss: 0.5364\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5254 - val_loss: 0.5370\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5338 - val_loss: 0.5362\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5284 - val_loss: 0.5358\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5215 - val_loss: 0.5354\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5227 - val_loss: 0.5355\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5131 - val_loss: 0.5368\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5350 - val_loss: 0.5362\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5346 - val_loss: 0.5370\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5265 - val_loss: 0.5360\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5354 - val_loss: 0.5355\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5332 - val_loss: 0.5354\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5326 - val_loss: 0.5364\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5212 - val_loss: 0.5357\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5260 - val_loss: 0.5369\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5282 - val_loss: 0.5369\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5099 - val_loss: 0.5357\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5291 - val_loss: 0.5356\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.5598\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 6.4225 - val_loss: 3.4532\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 3.0125 - val_loss: 1.7593\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 1.5895 - val_loss: 1.0679\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.9884 - val_loss: 0.7827\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.7302 - val_loss: 0.6648\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.6828 - val_loss: 0.6119\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5805 - val_loss: 0.5872\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5834 - val_loss: 0.5754\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5760 - val_loss: 0.5694\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5903 - val_loss: 0.5656\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5695 - val_loss: 0.5617\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5712 - val_loss: 0.5605\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5680 - val_loss: 0.5574\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5842 - val_loss: 0.5565\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5662 - val_loss: 0.5557\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5879 - val_loss: 0.5536\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5585 - val_loss: 0.5540\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5988 - val_loss: 0.5531\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5947 - val_loss: 0.5513\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5772 - val_loss: 0.5518\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5752 - val_loss: 0.5524\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5546 - val_loss: 0.5525\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5524 - val_loss: 0.5512\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5312 - val_loss: 0.5523\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5514 - val_loss: 0.5515\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5646 - val_loss: 0.5523\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5323 - val_loss: 0.5544\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5581 - val_loss: 0.5549\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5347 - val_loss: 0.5566\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5388 - val_loss: 0.5579\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5628 - val_loss: 0.5589\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5405 - val_loss: 0.5608\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5451 - val_loss: 0.5612\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.5545\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 5.9245 - val_loss: 2.9821\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.4560 - val_loss: 1.6328\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 1.3896 - val_loss: 1.0908\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.9953 - val_loss: 0.8599\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.7916 - val_loss: 0.7552\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.7121 - val_loss: 0.7045\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.7013 - val_loss: 0.6766\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6868 - val_loss: 0.6598\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6309 - val_loss: 0.6484\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6364 - val_loss: 0.6391\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.6204 - val_loss: 0.6318\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6479 - val_loss: 0.6252\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.6384 - val_loss: 0.6194\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.6316 - val_loss: 0.6140\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6079 - val_loss: 0.6091\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6037 - val_loss: 0.6045\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6111 - val_loss: 0.6001\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5748 - val_loss: 0.5961\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6138 - val_loss: 0.5923\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5604 - val_loss: 0.5887\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5804 - val_loss: 0.5854\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5937 - val_loss: 0.5823\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5910 - val_loss: 0.5796\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5676 - val_loss: 0.5766\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5840 - val_loss: 0.5740\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5613 - val_loss: 0.5716\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5636 - val_loss: 0.5692\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5840 - val_loss: 0.5671\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5591 - val_loss: 0.5652\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5731 - val_loss: 0.5631\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5670 - val_loss: 0.5611\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5508 - val_loss: 0.5595\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5463 - val_loss: 0.5581\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5543 - val_loss: 0.5567\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5496 - val_loss: 0.5551\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5292 - val_loss: 0.5536\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5571 - val_loss: 0.5522\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5616 - val_loss: 0.5512\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5480 - val_loss: 0.5502\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.5566 - val_loss: 0.5491\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5643 - val_loss: 0.5483\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5499 - val_loss: 0.5472\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5710 - val_loss: 0.5463\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5453 - val_loss: 0.5454\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5487 - val_loss: 0.5447\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5435 - val_loss: 0.5436\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5865 - val_loss: 0.5428\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5341 - val_loss: 0.5421\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5341 - val_loss: 0.5414\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5821 - val_loss: 0.5410\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5379 - val_loss: 0.5407\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5355 - val_loss: 0.5401\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5346 - val_loss: 0.5395\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5388 - val_loss: 0.5388\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5434 - val_loss: 0.5387\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5387 - val_loss: 0.5381\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5319 - val_loss: 0.5379\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5375 - val_loss: 0.5374\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5155 - val_loss: 0.5370\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5464 - val_loss: 0.5369\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5640 - val_loss: 0.5364\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5490 - val_loss: 0.5362\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5245 - val_loss: 0.5358\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5190 - val_loss: 0.5353\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5432 - val_loss: 0.5352\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5557 - val_loss: 0.5351\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5360 - val_loss: 0.5349\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5440 - val_loss: 0.5350\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5404 - val_loss: 0.5345\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5417 - val_loss: 0.5344\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5453 - val_loss: 0.5342\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5666 - val_loss: 0.5340\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5342 - val_loss: 0.5338\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5489 - val_loss: 0.5337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5369 - val_loss: 0.5335\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5349 - val_loss: 0.5333\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5342 - val_loss: 0.5333\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5501 - val_loss: 0.5331\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5424 - val_loss: 0.5329\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5317 - val_loss: 0.5328\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5473 - val_loss: 0.5327\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5357 - val_loss: 0.5327\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5217 - val_loss: 0.5326\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5406 - val_loss: 0.5324\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5307 - val_loss: 0.5323\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5203 - val_loss: 0.5320\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5257 - val_loss: 0.5322\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5396 - val_loss: 0.5324\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5117 - val_loss: 0.5321\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5215 - val_loss: 0.5320\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5379 - val_loss: 0.5321\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5334 - val_loss: 0.5320\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5384 - val_loss: 0.5318\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5389 - val_loss: 0.5318\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5236 - val_loss: 0.5319\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5222 - val_loss: 0.5316\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5459 - val_loss: 0.5316\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5234 - val_loss: 0.5315\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5471 - val_loss: 0.5315\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5281 - val_loss: 0.5314\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.5473\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 2.0800 - val_loss: 9.4508\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 25.6924 - val_loss: 444.7316\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 578.4285 - val_loss: 22754.5820\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 96676.9702 - val_loss: 1164351.2500\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 4343954.6855 - val_loss: 59552044.0000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 16300696.1408 - val_loss: 3060515072.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 2328898315.7305 - val_loss: 156618768384.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 99789670199.4403 - val_loss: 7997622845440.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 5866631370726.7158 - val_loss: 408914675892224.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 621080761299938.5000 - val_loss: 20924526615330816.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 33978432989441628.0000 - val_loss: 1070484108485853184.0000\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 18427458399240192.0000\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 2.7280 - val_loss: 0.8541\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5468 - val_loss: 0.8959\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5287 - val_loss: 0.9501\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5412 - val_loss: 1.0168\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5447 - val_loss: 1.0680\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5566 - val_loss: 1.1430\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5285 - val_loss: 1.1830\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5580 - val_loss: 1.2334\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5377 - val_loss: 1.2904\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5526 - val_loss: 1.3423\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5179 - val_loss: 1.4337\n",
      "121/121 [==============================] - 1s 3ms/step - loss: 2.5440\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 2.3247 - val_loss: 3.3086\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 2.1387 - val_loss: 139.2404\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 141.8976 - val_loss: 6725.8335\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 13429.3834 - val_loss: 329230.2812\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 428480.8228 - val_loss: 16099348.0000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 8773664.1016 - val_loss: 791367360.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 1459470910.0772 - val_loss: 38559227904.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 68838768406.0576 - val_loss: 1885147758592.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 1265498604333.3003 - val_loss: 92980211875840.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 90497034893606.9844 - val_loss: 4536394387030016.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 14552606975792672.0000 - val_loss: 222283008747503616.0000\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 2461015455301632.0000\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 2.1195 - val_loss: 0.8049\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.8829 - val_loss: 0.5700\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5162 - val_loss: 0.5140\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4749 - val_loss: 0.4799\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4620 - val_loss: 0.4632\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4453 - val_loss: 0.4444\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4479 - val_loss: 0.4295\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4344 - val_loss: 0.4235\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4021 - val_loss: 0.4113\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3822 - val_loss: 0.4058\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3977 - val_loss: 0.3976\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3821 - val_loss: 0.3940\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3854 - val_loss: 0.3872\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3796 - val_loss: 0.4033\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3723 - val_loss: 0.3816\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3634 - val_loss: 0.3783\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3723 - val_loss: 0.3747\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3625 - val_loss: 0.3720\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3435 - val_loss: 0.3771\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3596 - val_loss: 0.3657\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3441 - val_loss: 0.3706\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3258 - val_loss: 0.3567\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3448 - val_loss: 0.3552\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3381 - val_loss: 0.3552\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3297 - val_loss: 0.3479\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3344 - val_loss: 0.3447\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3185 - val_loss: 0.3768\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3307 - val_loss: 0.3417\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.3408 - val_loss: 0.3532\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3180 - val_loss: 0.3483\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3200 - val_loss: 0.3410\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3190 - val_loss: 0.3350\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3189 - val_loss: 0.3387\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3242 - val_loss: 0.3311\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3239 - val_loss: 0.3338\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3174 - val_loss: 0.3331\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3267 - val_loss: 0.3318\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3260 - val_loss: 0.3262\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3071 - val_loss: 0.3315\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3063 - val_loss: 0.3244\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2928 - val_loss: 0.3381\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2960 - val_loss: 0.3269\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3068 - val_loss: 0.3229\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2988 - val_loss: 0.3316\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3155 - val_loss: 0.3280\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2968 - val_loss: 0.3266\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2908 - val_loss: 0.3218\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3049 - val_loss: 0.3255\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3097 - val_loss: 0.3305\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2990 - val_loss: 0.3333\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2990 - val_loss: 0.3230\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2912 - val_loss: 0.3180\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.2884 - val_loss: 0.3117\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.2992 - val_loss: 0.3195\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3040 - val_loss: 0.3134\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2844 - val_loss: 0.3098\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2858 - val_loss: 0.3096\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.2927 - val_loss: 0.3199\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.2841 - val_loss: 0.3264\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3094 - val_loss: 0.3132\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2837 - val_loss: 0.3095\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.2982 - val_loss: 0.3134\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.2989 - val_loss: 0.3193\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.2844 - val_loss: 0.3068\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.2708 - val_loss: 0.3074\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.2849 - val_loss: 0.3153\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2708 - val_loss: 0.3125\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2906 - val_loss: 0.3092\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2932 - val_loss: 0.3163\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2761 - val_loss: 0.3175\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2868 - val_loss: 0.3152\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2774 - val_loss: 0.3107\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2862 - val_loss: 0.3087\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2648 - val_loss: 0.3106\n",
      "121/121 [==============================] - 1s 3ms/step - loss: 0.3342\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 1.7633 - val_loss: 0.7100\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.6100 - val_loss: 0.5755\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5397 - val_loss: 0.5104\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4895 - val_loss: 0.4959\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4405 - val_loss: 0.4550\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4664 - val_loss: 0.4417\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4407 - val_loss: 0.4321\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4145 - val_loss: 0.4174\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4291 - val_loss: 0.4119\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.4145 - val_loss: 0.4051\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3983 - val_loss: 0.4032\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3922 - val_loss: 0.3985\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4022 - val_loss: 0.3909\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3754 - val_loss: 0.3888\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3900 - val_loss: 0.3871\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3918 - val_loss: 0.3819\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3867 - val_loss: 0.3874\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3647 - val_loss: 0.3738\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3864 - val_loss: 0.3725\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.3784 - val_loss: 0.3708\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3660 - val_loss: 0.3719\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3700 - val_loss: 0.3737\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3446 - val_loss: 0.3732\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3561 - val_loss: 0.3673\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3453 - val_loss: 0.3769\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3428 - val_loss: 0.3760\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3495 - val_loss: 0.3726\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3247 - val_loss: 0.3855\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3539 - val_loss: 0.3906\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3622 - val_loss: 0.3829\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3346 - val_loss: 0.3902\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3459 - val_loss: 0.3942\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 3s 10ms/step - loss: 0.3075 - val_loss: 0.4256\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3196 - val_loss: 0.4016\n",
      "121/121 [==============================] - 1s 4ms/step - loss: 0.5334\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 3s 8ms/step - loss: 2.0737 - val_loss: 0.6825\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5982 - val_loss: 0.6989\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.6184 - val_loss: 0.5360\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.5393 - val_loss: 0.4810\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4833 - val_loss: 0.4612\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4618 - val_loss: 0.4475\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4185 - val_loss: 0.4273\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4350 - val_loss: 0.4212\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4022 - val_loss: 0.4116\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3950 - val_loss: 0.4070\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4070 - val_loss: 0.3959\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.3942 - val_loss: 0.3857\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.3931 - val_loss: 0.3854\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3724 - val_loss: 0.3816\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3734 - val_loss: 0.3724\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3705 - val_loss: 0.3671\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3545 - val_loss: 0.3694\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3632 - val_loss: 0.3623\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3961 - val_loss: 0.3853\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3562 - val_loss: 0.3713\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3810 - val_loss: 0.3641\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3660 - val_loss: 0.3503\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3500 - val_loss: 0.3490\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3440 - val_loss: 0.3450\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3660 - val_loss: 0.3414\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3493 - val_loss: 0.3364\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3518 - val_loss: 0.3398\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3296 - val_loss: 0.3416\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3241 - val_loss: 0.3598\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3553 - val_loss: 0.3510\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3294 - val_loss: 0.3364\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3355 - val_loss: 0.3393\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3232 - val_loss: 0.3373\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3141 - val_loss: 0.3242\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3327 - val_loss: 0.3242\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3191 - val_loss: 0.3256\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3448 - val_loss: 0.3271\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3242 - val_loss: 0.3295\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3130 - val_loss: 0.3314\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3311 - val_loss: 0.3274\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3428 - val_loss: 0.3451\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3290 - val_loss: 0.3223\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3271 - val_loss: 0.3393\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3139 - val_loss: 0.3145\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3004 - val_loss: 0.3227\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3131 - val_loss: 0.3204\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3081 - val_loss: 0.3105\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3021 - val_loss: 0.3101\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3019 - val_loss: 0.3131\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3031 - val_loss: 0.3116\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2896 - val_loss: 0.3092\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3056 - val_loss: 0.3320\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3048 - val_loss: 0.3128\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3111 - val_loss: 0.3196\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2934 - val_loss: 0.3277\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2919 - val_loss: 0.3109\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.2956 - val_loss: 0.3056\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2812 - val_loss: 0.3063\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2821 - val_loss: 0.3095\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2979 - val_loss: 0.3043\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2954 - val_loss: 0.3134\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2998 - val_loss: 0.3082\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2801 - val_loss: 0.3088\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2820 - val_loss: 0.3099\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.2927 - val_loss: 0.3214\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.2950 - val_loss: 0.3196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2850 - val_loss: 0.3073\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2883 - val_loss: 0.3026\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2767 - val_loss: 0.3070\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2994 - val_loss: 0.3176\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2926 - val_loss: 0.3054\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3008 - val_loss: 0.3252\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3132 - val_loss: 0.3012\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2789 - val_loss: 0.3106\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2866 - val_loss: 0.3060\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2976 - val_loss: 0.3061\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.2726 - val_loss: 0.2997\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 3s 10ms/step - loss: 0.2702 - val_loss: 0.3073\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2803 - val_loss: 0.3100\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2799 - val_loss: 0.3110\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.2901 - val_loss: 0.3006\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.2782 - val_loss: 0.2987\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2666 - val_loss: 0.2979\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.2798 - val_loss: 0.3045\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.2682 - val_loss: 0.3139\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.2696 - val_loss: 0.2988\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.2898 - val_loss: 0.3052\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2719 - val_loss: 0.3069\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.2891 - val_loss: 0.3057\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.2552 - val_loss: 0.3089\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.2769 - val_loss: 0.3072\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2684 - val_loss: 0.3024\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.2811 - val_loss: 0.3190\n",
      "121/121 [==============================] - 1s 4ms/step - loss: 0.3233\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 3s 8ms/step - loss: 2.4727 - val_loss: 1.1251\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 1.9381 - val_loss: 0.6894\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6479 - val_loss: 0.6288\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5914 - val_loss: 0.5865\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5328 - val_loss: 0.5525\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.5160 - val_loss: 0.5403\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.5200 - val_loss: 0.5187\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.5184 - val_loss: 0.5082\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4934 - val_loss: 0.5106\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4960 - val_loss: 0.4907\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4971 - val_loss: 0.4853\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4826 - val_loss: 0.4831\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4468 - val_loss: 0.4859\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4495 - val_loss: 0.4928\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4700 - val_loss: 0.4834\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4536 - val_loss: 0.4643\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4531 - val_loss: 0.4632\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4578 - val_loss: 0.4620\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4500 - val_loss: 0.4563\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4564 - val_loss: 0.4528\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4387 - val_loss: 0.4505\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4367 - val_loss: 0.4498\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4322 - val_loss: 0.4456\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4236 - val_loss: 0.4418\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4098 - val_loss: 0.4428\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4401 - val_loss: 0.4392\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4607 - val_loss: 0.4382\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4162 - val_loss: 0.4359\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4180 - val_loss: 0.4340\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4207 - val_loss: 0.4316\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4213 - val_loss: 0.4310\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4447 - val_loss: 0.4289\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4036 - val_loss: 0.4276\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4308 - val_loss: 0.4226\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4112 - val_loss: 0.4236\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3904 - val_loss: 0.4200\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4127 - val_loss: 0.4192\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4313 - val_loss: 0.4163\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4174 - val_loss: 0.4158\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4041 - val_loss: 0.4148\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4096 - val_loss: 0.4124\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4160 - val_loss: 0.4109\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3916 - val_loss: 0.4104\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4015 - val_loss: 0.4097\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3952 - val_loss: 0.4079\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3979 - val_loss: 0.4089\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4240 - val_loss: 0.4051\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4173 - val_loss: 0.4045\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4040 - val_loss: 0.4063\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3784 - val_loss: 0.4085\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4027 - val_loss: 0.4033\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4032 - val_loss: 0.4013\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3979 - val_loss: 0.3992\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4058 - val_loss: 0.4007\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4032 - val_loss: 0.4001\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3927 - val_loss: 0.3972\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3966 - val_loss: 0.3960\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4112 - val_loss: 0.3959\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3854 - val_loss: 0.3938\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3857 - val_loss: 0.3919\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3770 - val_loss: 0.3934\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3698 - val_loss: 0.3934\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3926 - val_loss: 0.3927\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3940 - val_loss: 0.3914\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3843 - val_loss: 0.3884\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3847 - val_loss: 0.3902\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4012 - val_loss: 0.3863\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3824 - val_loss: 0.3895\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3847 - val_loss: 0.3881\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3611 - val_loss: 0.3844\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3804 - val_loss: 0.3839\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3738 - val_loss: 0.3849\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3901 - val_loss: 0.3872\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4030 - val_loss: 0.3869\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3770 - val_loss: 0.3827\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3723 - val_loss: 0.3885\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3959 - val_loss: 0.3808\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3726 - val_loss: 0.3941\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3835 - val_loss: 0.3820\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3751 - val_loss: 0.3829\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3631 - val_loss: 0.3803\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3703 - val_loss: 0.3771\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3715 - val_loss: 0.3774\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3682 - val_loss: 0.3759\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3710 - val_loss: 0.3808\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3750 - val_loss: 0.3764\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3756 - val_loss: 0.3766\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3649 - val_loss: 0.3772\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3604 - val_loss: 0.3759\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3834 - val_loss: 0.3809\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3672 - val_loss: 0.3754\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3500 - val_loss: 0.3721\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3649 - val_loss: 0.3743\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3652 - val_loss: 0.3743\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3667 - val_loss: 0.3710\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3699 - val_loss: 0.3706\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3516 - val_loss: 0.3689\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3621 - val_loss: 0.3714\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3480 - val_loss: 0.3672\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3662 - val_loss: 0.3741\n",
      "121/121 [==============================] - 1s 4ms/step - loss: 0.4000\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 3s 8ms/step - loss: 2.2188 - val_loss: 0.9623\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.7057 - val_loss: 0.7746\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6398 - val_loss: 0.6592\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.5616 - val_loss: 0.5871\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.5372 - val_loss: 0.5417\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5104 - val_loss: 0.5147\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5118 - val_loss: 0.4968\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4843 - val_loss: 0.4868\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4834 - val_loss: 0.4797\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4815 - val_loss: 0.4798\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4740 - val_loss: 0.4735\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4702 - val_loss: 0.4777\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4958 - val_loss: 0.4802\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4458 - val_loss: 0.4809\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4504 - val_loss: 0.4823\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4563 - val_loss: 0.4891\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4598 - val_loss: 0.4868\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4484 - val_loss: 0.4862\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4711 - val_loss: 0.4922\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4700 - val_loss: 0.5019\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4442 - val_loss: 0.4969\n",
      "121/121 [==============================] - 1s 4ms/step - loss: 0.5465\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 1.7875 - val_loss: 0.8427\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.7792 - val_loss: 0.8763\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.9259 - val_loss: 0.7824\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.7941 - val_loss: 0.6054\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5864 - val_loss: 0.5652\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5478 - val_loss: 0.5362\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5050 - val_loss: 0.5147\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4991 - val_loss: 0.4995\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4892 - val_loss: 0.4909\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4916 - val_loss: 0.4786\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4884 - val_loss: 0.4743\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4786 - val_loss: 0.4667\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4522 - val_loss: 0.4618\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4506 - val_loss: 0.4556\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4321 - val_loss: 0.4528\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4541 - val_loss: 0.4481\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4519 - val_loss: 0.4453\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4607 - val_loss: 0.4415\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4408 - val_loss: 0.4396\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4383 - val_loss: 0.4372\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4346 - val_loss: 0.4332\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4516 - val_loss: 0.4290\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4477 - val_loss: 0.4281\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4246 - val_loss: 0.4278\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4354 - val_loss: 0.4251\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4230 - val_loss: 0.4195\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4235 - val_loss: 0.4179\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4373 - val_loss: 0.4166\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4180 - val_loss: 0.4163\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4107 - val_loss: 0.4143\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4137 - val_loss: 0.4107\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4203 - val_loss: 0.4108\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4083 - val_loss: 0.4079\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4105 - val_loss: 0.4102\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4174 - val_loss: 0.4055\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4200 - val_loss: 0.4035\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3936 - val_loss: 0.4009\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4030 - val_loss: 0.3990\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4214 - val_loss: 0.4003\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4039 - val_loss: 0.3965\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3955 - val_loss: 0.3967\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3896 - val_loss: 0.3956\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4021 - val_loss: 0.3938\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3927 - val_loss: 0.3927\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3902 - val_loss: 0.3927\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3954 - val_loss: 0.3889\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4041 - val_loss: 0.3923\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4001 - val_loss: 0.3876\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3809 - val_loss: 0.3860\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3842 - val_loss: 0.3845\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3892 - val_loss: 0.3862\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3862 - val_loss: 0.3839\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3830 - val_loss: 0.3827\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4011 - val_loss: 0.3834\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3872 - val_loss: 0.3809\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3942 - val_loss: 0.3821\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3799 - val_loss: 0.3795\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3912 - val_loss: 0.3778\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3749 - val_loss: 0.3773\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3755 - val_loss: 0.3790\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3791 - val_loss: 0.3752\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3680 - val_loss: 0.3751\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3888 - val_loss: 0.3782\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3613 - val_loss: 0.3766\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3860 - val_loss: 0.3746\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3699 - val_loss: 0.3717\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3879 - val_loss: 0.3732\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3697 - val_loss: 0.3690\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3510 - val_loss: 0.3693\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3606 - val_loss: 0.3750\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3705 - val_loss: 0.3707\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3836 - val_loss: 0.3730\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3827 - val_loss: 0.3674\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3544 - val_loss: 0.3673\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3733 - val_loss: 0.3661\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3655 - val_loss: 0.3678\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3765 - val_loss: 0.3706\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3720 - val_loss: 0.3640\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3807 - val_loss: 0.3639\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3686 - val_loss: 0.3648\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3773 - val_loss: 0.3629\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3607 - val_loss: 0.3619\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3714 - val_loss: 0.3622\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3576 - val_loss: 0.3612\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3759 - val_loss: 0.3614\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3747 - val_loss: 0.3608\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3787 - val_loss: 0.3613\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3576 - val_loss: 0.3597\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3627 - val_loss: 0.3613\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3514 - val_loss: 0.3601\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3573 - val_loss: 0.3583\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3535 - val_loss: 0.3564\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3669 - val_loss: 0.3602\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3590 - val_loss: 0.3580\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3599 - val_loss: 0.3588\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3495 - val_loss: 0.3561\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.3507 - val_loss: 0.3569\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3537 - val_loss: 0.3534\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3535 - val_loss: 0.3538\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3468 - val_loss: 0.3529\n",
      "121/121 [==============================] - 1s 4ms/step - loss: 0.3708\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 4.1312 - val_loss: 2.3344\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 1.7474 - val_loss: 1.0676\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.9788 - val_loss: 0.8771\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.8153 - val_loss: 0.7809\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.6862 - val_loss: 0.7265\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6904 - val_loss: 0.6931\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6373 - val_loss: 0.6712\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6231 - val_loss: 0.6500\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.6276 - val_loss: 0.6346\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6074 - val_loss: 0.6198\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.5446 - val_loss: 0.6100\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5352 - val_loss: 0.5962\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5613 - val_loss: 0.5870\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.5679 - val_loss: 0.5762\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5198 - val_loss: 0.5693\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5333 - val_loss: 0.5625\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5304 - val_loss: 0.5539\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5041 - val_loss: 0.5489\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5344 - val_loss: 0.5425\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4947 - val_loss: 0.5343\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5090 - val_loss: 0.5306\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4781 - val_loss: 0.5242\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.5058 - val_loss: 0.5194\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4855 - val_loss: 0.5148\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4957 - val_loss: 0.5134\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4779 - val_loss: 0.5062\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4676 - val_loss: 0.5029\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4540 - val_loss: 0.5013\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4481 - val_loss: 0.4977\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4761 - val_loss: 0.4963\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4544 - val_loss: 0.4940\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4615 - val_loss: 0.4892\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4674 - val_loss: 0.4884\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4645 - val_loss: 0.4876\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4510 - val_loss: 0.4816\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4559 - val_loss: 0.4826\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4341 - val_loss: 0.4787\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4557 - val_loss: 0.4754\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4437 - val_loss: 0.4751\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4561 - val_loss: 0.4720\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4540 - val_loss: 0.4703\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4296 - val_loss: 0.4677\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4329 - val_loss: 0.4676\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4418 - val_loss: 0.4670\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4375 - val_loss: 0.4653\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4335 - val_loss: 0.4642\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4215 - val_loss: 0.4614\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4318 - val_loss: 0.4610\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4348 - val_loss: 0.4583\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4287 - val_loss: 0.4566\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4175 - val_loss: 0.4559\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4306 - val_loss: 0.4565\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4515 - val_loss: 0.4529\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4305 - val_loss: 0.4519\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4310 - val_loss: 0.4511\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4239 - val_loss: 0.4500\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4048 - val_loss: 0.4487\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4216 - val_loss: 0.4477\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4295 - val_loss: 0.4473\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4209 - val_loss: 0.4468\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4290 - val_loss: 0.4460\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4227 - val_loss: 0.4454\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4076 - val_loss: 0.4419\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4350 - val_loss: 0.4435\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4076 - val_loss: 0.4389\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4196 - val_loss: 0.4398\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4283 - val_loss: 0.4407\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4199 - val_loss: 0.4376\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4155 - val_loss: 0.4373\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4121 - val_loss: 0.4368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4217 - val_loss: 0.4345\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4190 - val_loss: 0.4341\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4257 - val_loss: 0.4336\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3903 - val_loss: 0.4300\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4047 - val_loss: 0.4317\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4079 - val_loss: 0.4303\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4051 - val_loss: 0.4287\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4065 - val_loss: 0.4273\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4055 - val_loss: 0.4280\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4315 - val_loss: 0.4278\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3925 - val_loss: 0.4249\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3965 - val_loss: 0.4242\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3914 - val_loss: 0.4240\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3961 - val_loss: 0.4247\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3894 - val_loss: 0.4222\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4110 - val_loss: 0.4238\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4176 - val_loss: 0.4200\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3904 - val_loss: 0.4213\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3852 - val_loss: 0.4210\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.4011 - val_loss: 0.4205\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3994 - val_loss: 0.4175\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4000 - val_loss: 0.4175\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4181 - val_loss: 0.4191\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3699 - val_loss: 0.4151\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3884 - val_loss: 0.4166\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4017 - val_loss: 0.4169\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3714 - val_loss: 0.4150\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3884 - val_loss: 0.4155\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4048 - val_loss: 0.4144\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3795 - val_loss: 0.4142\n",
      "121/121 [==============================] - 1s 3ms/step - loss: 0.4376\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 4.2233 - val_loss: 2.1467\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 1.7594 - val_loss: 1.4943\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 1.1046 - val_loss: 1.3034\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.8854 - val_loss: 1.2002\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.7361 - val_loss: 1.1554\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.7175 - val_loss: 1.1128\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.6769 - val_loss: 1.0793\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.6815 - val_loss: 1.0491\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.6659 - val_loss: 1.0152\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6456 - val_loss: 0.9890\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.6570 - val_loss: 0.9545\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.6334 - val_loss: 0.9327\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6111 - val_loss: 0.9076\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5955 - val_loss: 0.8825\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5813 - val_loss: 0.8598\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5937 - val_loss: 0.8350\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.5855 - val_loss: 0.8164\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.5879 - val_loss: 0.7923\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5577 - val_loss: 0.7746\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.5610 - val_loss: 0.7558\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.5332 - val_loss: 0.7381\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5544 - val_loss: 0.7193\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.5323 - val_loss: 0.7035\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.5451 - val_loss: 0.6895\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.5310 - val_loss: 0.6718\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.5386 - val_loss: 0.6567\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.5109 - val_loss: 0.6423\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.5190 - val_loss: 0.6295\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5230 - val_loss: 0.6189\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5290 - val_loss: 0.6072\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5075 - val_loss: 0.5984\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4906 - val_loss: 0.5877\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5091 - val_loss: 0.5789\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5155 - val_loss: 0.5691\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.5261 - val_loss: 0.5610\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5001 - val_loss: 0.5541\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4918 - val_loss: 0.5467\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 3s 10ms/step - loss: 0.4931 - val_loss: 0.5404\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4960 - val_loss: 0.5339\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4713 - val_loss: 0.5282\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4897 - val_loss: 0.5228\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.5011 - val_loss: 0.5179\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4817 - val_loss: 0.5129\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4766 - val_loss: 0.5087\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4737 - val_loss: 0.5043\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4480 - val_loss: 0.4999\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4606 - val_loss: 0.4958\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 3s 10ms/step - loss: 0.4711 - val_loss: 0.4920\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.5000 - val_loss: 0.4885\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5007 - val_loss: 0.4851\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.4858 - val_loss: 0.4818\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4490 - val_loss: 0.4784\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4776 - val_loss: 0.4754\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4492 - val_loss: 0.4731\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4588 - val_loss: 0.4697\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4474 - val_loss: 0.4670\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5004 - val_loss: 0.4652\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4543 - val_loss: 0.4621\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4355 - val_loss: 0.4598\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4630 - val_loss: 0.4575\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4482 - val_loss: 0.4556\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4569 - val_loss: 0.4539\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4304 - val_loss: 0.4522\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4434 - val_loss: 0.4500\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4567 - val_loss: 0.4488\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4399 - val_loss: 0.4475\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4558 - val_loss: 0.4461\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4416 - val_loss: 0.4451\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4333 - val_loss: 0.4443\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4415 - val_loss: 0.4421\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4435 - val_loss: 0.4418\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4114 - val_loss: 0.4401\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4373 - val_loss: 0.4388\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4344 - val_loss: 0.4381\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4517 - val_loss: 0.4371\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4481 - val_loss: 0.4365\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4488 - val_loss: 0.4352\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4305 - val_loss: 0.4341\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4406 - val_loss: 0.4337\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4167 - val_loss: 0.4332\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4315 - val_loss: 0.4316\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4448 - val_loss: 0.4311\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4430 - val_loss: 0.4312\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4221 - val_loss: 0.4294\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4253 - val_loss: 0.4292\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4348 - val_loss: 0.4285\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4402 - val_loss: 0.4274\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4077 - val_loss: 0.4276\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4319 - val_loss: 0.4274\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4139 - val_loss: 0.4259\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4368 - val_loss: 0.4254\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4318 - val_loss: 0.4249\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4278 - val_loss: 0.4245\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4305 - val_loss: 0.4245\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4337 - val_loss: 0.4256\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4349 - val_loss: 0.4229\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4380 - val_loss: 0.4221\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4312 - val_loss: 0.4219\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4196 - val_loss: 0.4215\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4408 - val_loss: 0.4217\n",
      "121/121 [==============================] - 1s 3ms/step - loss: 0.4163\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 3s 9ms/step - loss: 4.0947 - val_loss: 1.8639\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 1.6979 - val_loss: 1.1823\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 1.1509 - val_loss: 0.9447\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.8889 - val_loss: 0.8280\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.7695 - val_loss: 0.7681\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.6978 - val_loss: 0.7345\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.7083 - val_loss: 0.7124\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6967 - val_loss: 0.6948\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.6528 - val_loss: 0.6794\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.6643 - val_loss: 0.6656\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.6531 - val_loss: 0.6534\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.6315 - val_loss: 0.6416\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6019 - val_loss: 0.6310\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6164 - val_loss: 0.6206\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5902 - val_loss: 0.6107\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5786 - val_loss: 0.6023\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5839 - val_loss: 0.5929\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5798 - val_loss: 0.5846\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5588 - val_loss: 0.5762\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5401 - val_loss: 0.5681\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5512 - val_loss: 0.5607\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5278 - val_loss: 0.5537\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5314 - val_loss: 0.5463\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5297 - val_loss: 0.5399\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5353 - val_loss: 0.5338\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4965 - val_loss: 0.5268\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5192 - val_loss: 0.5212\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5202 - val_loss: 0.5154\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5016 - val_loss: 0.5096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4892 - val_loss: 0.5050\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5123 - val_loss: 0.4992\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4863 - val_loss: 0.4943\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5085 - val_loss: 0.4903\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5054 - val_loss: 0.4858\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4728 - val_loss: 0.4813\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4532 - val_loss: 0.4767\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4609 - val_loss: 0.4730\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4839 - val_loss: 0.4707\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4782 - val_loss: 0.4669\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4465 - val_loss: 0.4638\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4583 - val_loss: 0.4608\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4368 - val_loss: 0.4580\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4639 - val_loss: 0.4558\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4313 - val_loss: 0.4536\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4294 - val_loss: 0.4517\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4539 - val_loss: 0.4494\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4514 - val_loss: 0.4474\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4415 - val_loss: 0.4463\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4326 - val_loss: 0.4436\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4281 - val_loss: 0.4422\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4396 - val_loss: 0.4403\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4475 - val_loss: 0.4392\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4394 - val_loss: 0.4372\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4311 - val_loss: 0.4362\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4342 - val_loss: 0.4352\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4314 - val_loss: 0.4338\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4185 - val_loss: 0.4324\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4454 - val_loss: 0.4322\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4173 - val_loss: 0.4302\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4367 - val_loss: 0.4295\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4520 - val_loss: 0.4293\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3954 - val_loss: 0.4271\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4326 - val_loss: 0.4266\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4087 - val_loss: 0.4253\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4312 - val_loss: 0.4255\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4106 - val_loss: 0.4243\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4093 - val_loss: 0.4226\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4166 - val_loss: 0.4218\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4242 - val_loss: 0.4223\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4112 - val_loss: 0.4197\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4254 - val_loss: 0.4194\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4255 - val_loss: 0.4189\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4333 - val_loss: 0.4180\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4047 - val_loss: 0.4168\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4064 - val_loss: 0.4173\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4181 - val_loss: 0.4161\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4289 - val_loss: 0.4150\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4196 - val_loss: 0.4148\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4110 - val_loss: 0.4149\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3875 - val_loss: 0.4128\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4007 - val_loss: 0.4120\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4098 - val_loss: 0.4124\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4131 - val_loss: 0.4102\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4082 - val_loss: 0.4103\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4195 - val_loss: 0.4098\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4042 - val_loss: 0.4084\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3976 - val_loss: 0.4084\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4118 - val_loss: 0.4074\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3977 - val_loss: 0.4059\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4059 - val_loss: 0.4059\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4089 - val_loss: 0.4058\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4124 - val_loss: 0.4062\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3983 - val_loss: 0.4043\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4135 - val_loss: 0.4039\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3919 - val_loss: 0.4031\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4051 - val_loss: 0.4031\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3967 - val_loss: 0.4032\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3909 - val_loss: 0.4025\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3934 - val_loss: 0.4007\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4286 - val_loss: 0.4003\n",
      "121/121 [==============================] - 1s 3ms/step - loss: 0.4090\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 1.9439 - val_loss: 12.4598\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.8022 - val_loss: 1605.9329\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 3248.6852 - val_loss: 193745.5625\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 4766.3500 - val_loss: 24142410.0000\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 7194214.8281 - val_loss: 2928438272.0000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 3813238925.7860 - val_loss: 355822993408.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 86005179107.8189 - val_loss: 43645629628416.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 60385572075410.4375 - val_loss: 5320066467889152.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 4038941556937193.0000 - val_loss: 651166313938419712.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 920664301966266880.0000 - val_loss: 79744332604268085248.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 169619852786507710464.0000 - val_loss: 10199669119475592986624.0000\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 175662041448470020096.0000\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 5ms/step - loss: 1.7534 - val_loss: 0.6710\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6185 - val_loss: 0.6400\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6099 - val_loss: 0.7219\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 1.6181 - val_loss: 0.8112\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5245 - val_loss: 0.9126\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5684 - val_loss: 1.0039\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 4.9502 - val_loss: 1.0764\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5391 - val_loss: 1.1698\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5750 - val_loss: 1.2345\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5146 - val_loss: 1.8717\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.7465 - val_loss: 1.3822\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5687 - val_loss: 1.4437\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 2.6817\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 5ms/step - loss: 2.3865 - val_loss: 20.8274\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 133.9798 - val_loss: 2297.0168\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 8972.9735 - val_loss: 263577.5625\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 242374.0944 - val_loss: 30262492.0000\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 235438544.5624 - val_loss: 3446675968.0000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 1946538455.0165 - val_loss: 402776031232.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 329476474270.0247 - val_loss: 45997904363520.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 19355063858551.0469 - val_loss: 5279747999268864.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 26667477418680352.0000 - val_loss: 603551894178103296.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 1127547470473633792.0000 - val_loss: 69183409070270316544.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 142838099903374229504.0000 - val_loss: 7926290871125752676352.0000\n",
      "121/121 [==============================] - 1s 4ms/step - loss: 87491764212461469696.0000\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 3s 8ms/step - loss: 4.0625 - val_loss: 2.3606\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 2.1810 - val_loss: 1.6294\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 1.6925 - val_loss: 1.2991\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 1.2684 - val_loss: 1.1110\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 1.0216 - val_loss: 0.9847\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.9212 - val_loss: 0.9053\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.8384 - val_loss: 0.8517\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.8188 - val_loss: 0.8139\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.7402 - val_loss: 0.7875\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.7249 - val_loss: 0.7660\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6949 - val_loss: 0.7466\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.6859 - val_loss: 0.7329\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.6928 - val_loss: 0.7171\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6581 - val_loss: 0.7049\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6610 - val_loss: 0.6918\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.6606 - val_loss: 0.6811\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.6376 - val_loss: 0.6695\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.6103 - val_loss: 0.6603\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6189 - val_loss: 0.6508\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6043 - val_loss: 0.6421\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5728 - val_loss: 0.6320\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5795 - val_loss: 0.6243\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.6073 - val_loss: 0.6177\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5646 - val_loss: 0.6098\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5842 - val_loss: 0.6021\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5833 - val_loss: 0.5977\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5447 - val_loss: 0.5894\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.5794 - val_loss: 0.5845\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5545 - val_loss: 0.5786\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.5640 - val_loss: 0.5740\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.5606 - val_loss: 0.5692\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.5459 - val_loss: 0.5634\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5247 - val_loss: 0.5585\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5273 - val_loss: 0.5545\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5311 - val_loss: 0.5502\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5233 - val_loss: 0.5465\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5470 - val_loss: 0.5432\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5266 - val_loss: 0.5381\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5240 - val_loss: 0.5367\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5171 - val_loss: 0.5336\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5081 - val_loss: 0.5286\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5072 - val_loss: 0.5256\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4930 - val_loss: 0.5221\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4843 - val_loss: 0.5195\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4902 - val_loss: 0.5188\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4889 - val_loss: 0.5158\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4975 - val_loss: 0.5126\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4669 - val_loss: 0.5099\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4977 - val_loss: 0.5084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4933 - val_loss: 0.5063\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4876 - val_loss: 0.5036\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5034 - val_loss: 0.5042\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4823 - val_loss: 0.5014\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4952 - val_loss: 0.5007\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5188 - val_loss: 0.4981\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4896 - val_loss: 0.4953\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4760 - val_loss: 0.4941\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4902 - val_loss: 0.4934\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4538 - val_loss: 0.4902\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4716 - val_loss: 0.4914\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4894 - val_loss: 0.4879\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4737 - val_loss: 0.4876\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4682 - val_loss: 0.4853\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4851 - val_loss: 0.4844\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4517 - val_loss: 0.4832\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4608 - val_loss: 0.4828\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4666 - val_loss: 0.4808\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4696 - val_loss: 0.4809\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4569 - val_loss: 0.4789\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4764 - val_loss: 0.4787\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4660 - val_loss: 0.4782\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4647 - val_loss: 0.4772\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4585 - val_loss: 0.4764\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4732 - val_loss: 0.4748\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4567 - val_loss: 0.4767\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4788 - val_loss: 0.4729\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4631 - val_loss: 0.4723\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4708 - val_loss: 0.4728\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4499 - val_loss: 0.4703\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4576 - val_loss: 0.4713\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4417 - val_loss: 0.4693\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4590 - val_loss: 0.4687\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4603 - val_loss: 0.4690\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4693 - val_loss: 0.4670\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4589 - val_loss: 0.4677\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4599 - val_loss: 0.4663\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4563 - val_loss: 0.4654\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4648 - val_loss: 0.4646\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4343 - val_loss: 0.4643\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4454 - val_loss: 0.4633\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4555 - val_loss: 0.4628\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4405 - val_loss: 0.4611\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4503 - val_loss: 0.4618\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4395 - val_loss: 0.4607\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4391 - val_loss: 0.4593\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4391 - val_loss: 0.4596\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4624 - val_loss: 0.4593\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4538 - val_loss: 0.4580\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4411 - val_loss: 0.4573\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4283 - val_loss: 0.4571\n",
      "121/121 [==============================] - 1s 3ms/step - loss: 0.4791\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 4.1172 - val_loss: 1.9645\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 1.6912 - val_loss: 1.2812\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 1.0673 - val_loss: 1.0576\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.9231 - val_loss: 0.9545\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.8400 - val_loss: 0.8939\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.7916 - val_loss: 0.8510\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.7759 - val_loss: 0.8191\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.7568 - val_loss: 0.7913\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.7186 - val_loss: 0.7698\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.7259 - val_loss: 0.7467\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6888 - val_loss: 0.7276\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6484 - val_loss: 0.7098\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6702 - val_loss: 0.6942\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.6741 - val_loss: 0.6800\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.6527 - val_loss: 0.6668\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.6357 - val_loss: 0.6546\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.6590 - val_loss: 0.6442\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6296 - val_loss: 0.6340\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6100 - val_loss: 0.6245\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.6023 - val_loss: 0.6162\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.6085 - val_loss: 0.6086\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5984 - val_loss: 0.6016\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5743 - val_loss: 0.5952\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5793 - val_loss: 0.5891\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5925 - val_loss: 0.5837\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5798 - val_loss: 0.5783\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5671 - val_loss: 0.5734\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5749 - val_loss: 0.5685\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5703 - val_loss: 0.5648\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5522 - val_loss: 0.5600\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5380 - val_loss: 0.5565\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5832 - val_loss: 0.5525\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5275 - val_loss: 0.5488\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5635 - val_loss: 0.5457\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5499 - val_loss: 0.5430\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5417 - val_loss: 0.5395\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5568 - val_loss: 0.5369\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.5494 - val_loss: 0.5353\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5534 - val_loss: 0.5317\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5438 - val_loss: 0.5299\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5286 - val_loss: 0.5284\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5365 - val_loss: 0.5257\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5107 - val_loss: 0.5231\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5137 - val_loss: 0.5217\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5419 - val_loss: 0.5205\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4815 - val_loss: 0.5186\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5096 - val_loss: 0.5169\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5099 - val_loss: 0.5143\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5201 - val_loss: 0.5125\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5014 - val_loss: 0.5107\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.5298 - val_loss: 0.5090\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4825 - val_loss: 0.5099\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5118 - val_loss: 0.5078\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4966 - val_loss: 0.5063\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4922 - val_loss: 0.5056\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.5240 - val_loss: 0.5063\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.4958 - val_loss: 0.5043\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5097 - val_loss: 0.5025\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4784 - val_loss: 0.5017\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4918 - val_loss: 0.5008\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4989 - val_loss: 0.5007\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5037 - val_loss: 0.5009\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4767 - val_loss: 0.4997\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4982 - val_loss: 0.4984\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4878 - val_loss: 0.4972\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4944 - val_loss: 0.4967\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4852 - val_loss: 0.4961\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4945 - val_loss: 0.4956\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4567 - val_loss: 0.4939\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4739 - val_loss: 0.4940\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4775 - val_loss: 0.4944\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4714 - val_loss: 0.4937\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4842 - val_loss: 0.4922\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4838 - val_loss: 0.4916\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4651 - val_loss: 0.4916\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4780 - val_loss: 0.4915\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4925 - val_loss: 0.4907\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4624 - val_loss: 0.4884\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4574 - val_loss: 0.4879\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4847 - val_loss: 0.4875\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4678 - val_loss: 0.4865\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4765 - val_loss: 0.4873\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4536 - val_loss: 0.4864\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4634 - val_loss: 0.4868\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4821 - val_loss: 0.4849\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4449 - val_loss: 0.4854\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4422 - val_loss: 0.4855\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4743 - val_loss: 0.4837\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4354 - val_loss: 0.4836\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4685 - val_loss: 0.4836\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4590 - val_loss: 0.4833\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4692 - val_loss: 0.4828\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4421 - val_loss: 0.4805\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4646 - val_loss: 0.4807\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4394 - val_loss: 0.4817\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4590 - val_loss: 0.4813\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4479 - val_loss: 0.4789\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4578 - val_loss: 0.4786\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4521 - val_loss: 0.4772\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4457 - val_loss: 0.4771\n",
      "121/121 [==============================] - 1s 4ms/step - loss: 0.4791\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 4.2917 - val_loss: 2.2493\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 1.9282 - val_loss: 1.3654\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 1.2667 - val_loss: 1.0813\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 1.0073 - val_loss: 0.9456\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.8841 - val_loss: 0.8676\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.8498 - val_loss: 0.8174\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.7752 - val_loss: 0.7856\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.7798 - val_loss: 0.7623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.7237 - val_loss: 0.7446\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6977 - val_loss: 0.7307\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.7045 - val_loss: 0.7181\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6856 - val_loss: 0.7068\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.6597 - val_loss: 0.6963\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.6796 - val_loss: 0.6872\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.6757 - val_loss: 0.6788\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.6637 - val_loss: 0.6702\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6137 - val_loss: 0.6619\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.6192 - val_loss: 0.6538\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.6400 - val_loss: 0.6468\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6266 - val_loss: 0.6394\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.6029 - val_loss: 0.6327\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.6189 - val_loss: 0.6258\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5978 - val_loss: 0.6192\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5957 - val_loss: 0.6126\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5921 - val_loss: 0.6066\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.6134 - val_loss: 0.6006\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5921 - val_loss: 0.5947\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5698 - val_loss: 0.5902\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5441 - val_loss: 0.5845\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5826 - val_loss: 0.5797\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5621 - val_loss: 0.5744\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5498 - val_loss: 0.5697\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5561 - val_loss: 0.5655\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5259 - val_loss: 0.5609\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5303 - val_loss: 0.5564\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5589 - val_loss: 0.5520\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5183 - val_loss: 0.5482\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5093 - val_loss: 0.5441\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5405 - val_loss: 0.5408\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5158 - val_loss: 0.5377\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5361 - val_loss: 0.5342\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5079 - val_loss: 0.5309\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5040 - val_loss: 0.5274\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5185 - val_loss: 0.5249\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4835 - val_loss: 0.5214\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4874 - val_loss: 0.5181\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4917 - val_loss: 0.5153\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5148 - val_loss: 0.5125\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4944 - val_loss: 0.5104\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4885 - val_loss: 0.5073\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4906 - val_loss: 0.5051\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5055 - val_loss: 0.5027\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4884 - val_loss: 0.5007\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4722 - val_loss: 0.4979\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5156 - val_loss: 0.4957\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4812 - val_loss: 0.4940\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4784 - val_loss: 0.4912\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4618 - val_loss: 0.4897\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4832 - val_loss: 0.4883\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4842 - val_loss: 0.4863\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4665 - val_loss: 0.4843\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4802 - val_loss: 0.4823\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4657 - val_loss: 0.4816\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4706 - val_loss: 0.4798\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4667 - val_loss: 0.4777\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4760 - val_loss: 0.4771\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4705 - val_loss: 0.4755\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4542 - val_loss: 0.4738\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4743 - val_loss: 0.4728\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4644 - val_loss: 0.4715\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4618 - val_loss: 0.4697\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4683 - val_loss: 0.4680\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4412 - val_loss: 0.4667\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4523 - val_loss: 0.4658\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4684 - val_loss: 0.4648\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4623 - val_loss: 0.4643\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4613 - val_loss: 0.4630\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4390 - val_loss: 0.4620\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4580 - val_loss: 0.4609\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4532 - val_loss: 0.4598\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4485 - val_loss: 0.4592\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4517 - val_loss: 0.4582\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4613 - val_loss: 0.4580\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4558 - val_loss: 0.4567\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4296 - val_loss: 0.4555\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4435 - val_loss: 0.4548\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4363 - val_loss: 0.4542\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4500 - val_loss: 0.4536\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4463 - val_loss: 0.4523\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4518 - val_loss: 0.4513\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4471 - val_loss: 0.4512\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4457 - val_loss: 0.4507\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4496 - val_loss: 0.4491\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4426 - val_loss: 0.4484\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4461 - val_loss: 0.4481\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4161 - val_loss: 0.4469\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4393 - val_loss: 0.4459\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4385 - val_loss: 0.4462\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4333 - val_loss: 0.4449\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4354 - val_loss: 0.4451\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.4652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vimukthi/anaconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the test scores are non-finite: [            nan -3.74021381e-01 -3.59915038e-01 -5.53867141e-01\n",
      " -6.96282462e+15 -3.96989028e-01 -4.39103107e-01 -4.20989424e-01\n",
      " -8.77179352e+19 -4.74463075e-01]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7f955b41b610>, as the constructor either does not set or modifies parameter learning_rate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7922/1552745566.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mrnd_search_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distribs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m rnd_search_cv.fit(X_train, y_train, epochs=100,\n\u001b[0m\u001b[1;32m     14\u001b[0m                  \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    874\u001b[0m             \u001b[0;31m# we clone again after setting params in case some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0;31m# of the params are estimators as well.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[0m\u001b[1;32m    877\u001b[0m                 **self.best_params_))\n\u001b[1;32m    878\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mparam2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam1\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparam2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[0m\u001b[1;32m     86\u001b[0m                                \u001b[0;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                                (estimator, name))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7f955b41b610>, as the constructor either does not set or modifies parameter learning_rate"
     ]
    }
   ],
   "source": [
    "# Randomized search for hyperparameter search space\n",
    "\n",
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                 validation_data=(X_valid, y_valid),\n",
    "                 callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bda4bd05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.005520512430789476, 'n_hidden': 3, 'n_neurons': 29}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0e3a2f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.35991503794987995"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
